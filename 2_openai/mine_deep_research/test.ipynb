{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0d876e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "import random\n",
    "from agents import Agent, ItemHelpers, Runner, function_tool\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51d479b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def how_many_jokes() -> int:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e616c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline of the joke\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1c9e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test():\n",
    "    agent = Agent(\n",
    "        name=\"Joker\",\n",
    "        instructions=\"First call the `how_many_jokes` tool, then tell that many jokes.\",\n",
    "        tools=[how_many_jokes],\n",
    "        output_type=Joke,\n",
    "    )\n",
    "\n",
    "    result = Runner.run_streamed(\n",
    "        agent,\n",
    "        input=\"Hello\",\n",
    "    )\n",
    "    print(\"=== Run starting ===\")\n",
    "\n",
    "    async for event in result.stream_events():\n",
    "        # We'll ignore the raw responses event deltas\n",
    "        if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "            # print(\"Event delta\")\n",
    "            print(event.data.delta, end=\"\", flush=True)\n",
    "        # When the agent updates, print that\n",
    "        elif event.type == \"agent_updated_stream_event\":\n",
    "            print(f\"Agent updated: {event.new_agent.name}\")\n",
    "            continue\n",
    "        # When items are generated, print them\n",
    "        elif event.type == \"run_item_stream_event\":\n",
    "            if event.item.type == \"tool_call_item\":\n",
    "                print(f\"-- Tool called: {event.item.raw_item.name}\")\n",
    "                print(f\"-- Tool args: {event.item.raw_item.arguments}\")\n",
    "                print(f\"-- Tool kwargs: {event.item}\")\n",
    "                print(\"-- Tool was called\")\n",
    "            elif event.item.type == \"tool_call_output_item\":\n",
    "                print(f\"-- Tool output: {event.item.output}\")\n",
    "            elif event.item.type == \"message_output_item\":\n",
    "                print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
    "                output = ItemHelpers.text_message_output(event.item)\n",
    "                parse_output = Joke.model_validate_json(output)\n",
    "                print(f\"Joke setup: {parse_output.setup}\")\n",
    "                print(f\"Joke punchline: {parse_output.punchline}\")\n",
    "            else:\n",
    "                pass  # Ignore other event types\n",
    "        else:\n",
    "            print(f\"Unknown event type: {event.type}\")\n",
    "\n",
    "    print(\"=== Run complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3e2aced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Run starting ===\n",
      "Agent updated: Joker\n",
      "Unknown event type: raw_response_event\n",
      "Unknown event type: raw_response_event\n",
      "Unknown event type: raw_response_event\n",
      "Unknown event type: raw_response_event\n",
      "Unknown event type: raw_response_event\n",
      "Unknown event type: raw_response_event\n",
      "Unknown event type: raw_response_event\n",
      "-- Tool called: how_many_jokes\n",
      "-- Tool args: {}\n",
      "-- Tool kwargs: ToolCallItem(agent=Agent(name='Joker', instructions='First call the `how_many_jokes` tool, then tell that many jokes.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None), tools=[FunctionTool(name='how_many_jokes', description='', params_json_schema={'properties': {}, 'title': 'how_many_jokes_args', 'type': 'object', 'additionalProperties': False, 'required': []}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x119d9a840>, strict_json_schema=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=<class '__main__.Joke'>, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{}', call_id='call_aVM8zM9X5fAOYu8TuxMW1e1X', name='how_many_jokes', type='function_call', id='fc_6825f01ac58c81919da05c60bcf1ed15085f2013ac726cf4', status='completed'), type='tool_call_item')\n",
      "-- Tool was called\n",
      "-- Tool output: 1\n",
      "Unknown event type: raw_response_event\n",
      "Unknown event type: raw_response_event\n",
      "Unknown event type: raw_response_event\n",
      "Unknown event type: raw_response_event\n",
      "{\"setup\":\"Why was the math book sad?\",\"punchline\":\"Because it had too many problems!\"}Unknown event type: raw_response_event\n",
      "Unknown event type: raw_response_event\n",
      "Unknown event type: raw_response_event\n",
      "Unknown event type: raw_response_event\n",
      "-- Message output:\n",
      " {\"setup\":\"Why was the math book sad?\",\"punchline\":\"Because it had too many problems!\"}\n",
      "Joke setup: Why was the math book sad?\n",
      "Joke punchline: Because it had too many problems!\n",
      "=== Run complete ===\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "output = await test()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa088e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a helpful research assistant. You will be given a task to solve as best you can.\n",
      "Given a query, come up with a set of web searches to perform to best answer the query.\n",
      "To solve the task, you must plan forward to proceed in a series of steps, in a cycle of 'Thought:', 'Queries:', and 'Observation:' sequences.\n",
      "At each step, in the 'Thought:' sequence, you should first explain your reasoning towards the web search.\n",
      "Then create a few web searches queries 'Queries' to perform to best answer the query.\n",
      "Then 'Observation:' to identify if the web searches would provide the information needed to answer the query.\n",
      "Here are a few examples:\n",
      "---\n",
      "Task: \"Which city has the highest population: Guangzhou or Shanghai?\"\n",
      "Thought: \"I need to get the populations for both cities and compare them.\"\n",
      "Queries: ['What is the population of Guangzhou', 'What is the population of Shanghai' ]\n",
      "Observation: These queries are enough to answer the question.\n",
      "---\n",
      "Task: \"What is the current age of the pope, raised to the power 0.36?\"\n",
      "Thought: \"I need to find the age of the pope\"\n",
      "Queries: [\"How is the current pope\", \"How old is the current pope\"]\n",
      "Observation: These queries are enough to answer the question, regarding the math calculation that is outside of my reach.\n",
      "\n",
      "Here are the rules you should always follow to solve your task:\n",
      "1. Always provide a 'Thought:' sequence, and a 'Queries:', 'Observation'.\n",
      "2. Only create the queries that will help with the search, you do not perform the search.\n",
      "3. Identify all the probable search queries that are relavant for the user query.\n",
      "4. Output 3 terms to query for.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "HOW_MANY_SEARCHES = 3\n",
    "prompt = dedent(\"\"\"\n",
    "  You are a helpful research assistant. You will be given a task to solve as best you can.\n",
    "  Given a query, come up with a set of web searches to perform to best answer the query.\n",
    "  To solve the task, you must plan forward to proceed in a series of steps, in a cycle of 'Thought:', 'Queries:', and 'Observation:' sequences.\n",
    "  At each step, in the 'Thought:' sequence, you should first explain your reasoning towards the web search.\n",
    "  Then create a few web searches queries 'Queries' to perform to best answer the query.\n",
    "  Then 'Observation:' to identify if the web searches would provide the information needed to answer the query.\n",
    "  Here are a few examples:\n",
    "  ---\n",
    "  Task: \"Which city has the highest population: Guangzhou or Shanghai?\"\n",
    "  Thought: \"I need to get the populations for both cities and compare them.\"\n",
    "  Queries: ['What is the population of Guangzhou', 'What is the population of Shanghai' ]\n",
    "  Observation: These queries are enough to answer the question.\n",
    "  ---\n",
    "  Task: \"What is the current age of the pope, raised to the power 0.36?\"\n",
    "  Thought: \"I need to find the age of the pope\"\n",
    "  Queries: [\"How is the current pope\", \"How old is the current pope\"]\n",
    "  Observation: These queries are enough to answer the question, regarding the math calculation that is outside of my reach.\n",
    "\n",
    "  Here are the rules you should always follow to solve your task:\n",
    "  1. Always provide a 'Thought:' sequence, and a 'Queries:', 'Observation'.\n",
    "  2. Only create the queries that will help with the search, you do not perform the search.\n",
    "  3. Identify all the probable search queries that are relavant for the user query.\n",
    "  4. Output {HOW_MANY_SEARCHES} terms to query for.\n",
    "\n",
    "\"\"\"\n",
    ").format(HOW_MANY_SEARCHES=HOW_MANY_SEARCHES)\n",
    "print(prompt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
