{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you were tasked with designing a new ethical framework for artificial intelligence, what key principles would you prioritize, and how would you ensure that these principles are implemented effectively across diverse applications and cultures?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Designing a new ethical framework for artificial intelligence (AI) is a complex task that requires careful consideration of various factors, including technological capabilities, societal implications, and cultural nuances. Here are the key principles I would prioritize, along with strategies for effective implementation:\n",
       "\n",
       "### Key Principles\n",
       "\n",
       "1. **Fairness and Non-Discrimination**:\n",
       "   - AI systems should be designed to avoid bias and discrimination against individuals based on race, gender, ethnicity, socio-economic status, or other protected characteristics.\n",
       "  \n",
       "2. **Transparency and Explainability**:\n",
       "   - AI decision-making processes should be transparent and understandable, enabling users to comprehend how decisions are made and the data involved.\n",
       "\n",
       "3. **Accountability**:\n",
       "   - Clear lines of accountability must be established for decisions made by AI systems, including responsibilities assigned to developers, operators, and organizations deploying AI technologies.\n",
       "\n",
       "4. **Privacy and Data Protection**:\n",
       "   - Individuals' privacy should be respected, ensuring that personal data is collected, stored, and processed with consent and in compliance with applicable regulations.\n",
       "\n",
       "5. **Safety and Security**:\n",
       "   - AI systems should be developed with a focus on minimizing potential harms or risks, both physical and psychological, ensuring robust security measures against misuse.\n",
       "\n",
       "6. **Human-Centric Design**:\n",
       "   - AI should augment human capabilities and rights, placing human well-being at the core of its design and deployment.\n",
       "\n",
       "7. **Sustainability**:\n",
       "   - The environmental impact of AI systems should be considered, encouraging energy-efficient practices and promoting sustainability in AI development.\n",
       "\n",
       "8. **Inclusivity**:\n",
       "   - Stakeholders from various backgrounds—including marginalized and vulnerable communities—should be included in the design and deployment processes to ensure diverse perspectives are considered.\n",
       "\n",
       "9. **Respect for Autonomy**:\n",
       "   - AI applications should respect human autonomy and dignity, allowing individuals to make informed choices without undue influence.\n",
       "\n",
       "10. **Adaptability and Continuous Learning**:\n",
       "    - The framework should be dynamic, allowing for adaptation as technology evolves and societal values change.\n",
       "\n",
       "### Implementation Strategies\n",
       "\n",
       "1. **Establishing Regulatory Bodies**:\n",
       "   - Create independent regulatory bodies that can oversee AI development and enforce compliance with the ethical framework. These bodies should include diverse representation from different cultural and societal backgrounds.\n",
       "\n",
       "2. **Global Collaboration**:\n",
       "   - Promote international cooperation and dialogue to align ethical standards internationally while being sensitive to localized cultural norms. This can include workshops, conferences, and collaborative research.\n",
       "\n",
       "3. **Education and Training**:\n",
       "   - Integrate ethical training into the curriculum for AI developers, engineers, and users, ensuring they understand the implications of their work and are equipped to uphold these principles.\n",
       "\n",
       "4. **Stakeholder Engagement**:\n",
       "   - Engage a wide range of stakeholders—including civil society, industry leaders, policymakers, and affected communities—in the development of AI to gather input and gain diverse insights.\n",
       "\n",
       "5. **Establishing best practices and guidelines**:\n",
       "   - Develop and disseminate best practices for implementing ethical principles in various AI applications across sectors, tailoring them to specific needs and cultural contexts.\n",
       "\n",
       "6. **Monitoring and Auditing**:\n",
       "   - Implement regular audits and assessments of AI systems to evaluate compliance with ethical standards, involving third-party reviewers to ensure objectivity.\n",
       "\n",
       "7. **Feedback Mechanisms**:\n",
       "   - Create channels for users and affected communities to provide feedback on AI systems, enabling ongoing dialogue about ethics and performance.\n",
       "\n",
       "8. **Funding and Support for Ethical Innovation**:\n",
       "   - Encourage funding for research and development of AI technologies that prioritize ethical considerations and social good, including grants and incentives for organizations dedicated to ethical AI.\n",
       "\n",
       "9. **Cultural Sensitivity Initiatives**:\n",
       "   - Develop resources and guidelines that incorporate an understanding of cultural differences in the adoption and perception of AI, ensuring principles respect and adapt to local customs and values.\n",
       "\n",
       "10. **Public Awareness Campaigns**:\n",
       "    - Conduct public awareness campaigns to educate communities about AI technologies and their implications, fostering informed public discourse and engagement.\n",
       "\n",
       "By prioritizing these principles and strategically implementing them through diverse channels, we can develop a robust ethical framework for AI that is adaptable, inclusive, and respectful of different cultures and contexts."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Designing a new ethical framework for AI requires a multi-faceted approach that prioritizes both core principles and their effective implementation across diverse contexts. Here's my proposed framework:\n",
       "\n",
       "**I. Core Principles:**\n",
       "\n",
       "1.  **Human-Centricity & Well-being:**  AI should prioritize human well-being, dignity, and rights.\n",
       "    *   **Focus:** AI systems should be designed and deployed in ways that improve human lives, promote equity, and avoid causing harm. This includes physical, psychological, economic, and social well-being.\n",
       "    *   **Application:**  AI-driven healthcare should improve patient outcomes and access. AI-powered education should personalize learning and reduce educational disparities. AI-based security systems should protect individuals without infringing on their civil liberties.\n",
       "\n",
       "2.  **Fairness, Equity, and Non-Discrimination:** AI systems must be fair and equitable, avoiding discriminatory outcomes based on protected characteristics (e.g., race, gender, religion, sexual orientation, disability).\n",
       "    *   **Focus:** Proactive identification and mitigation of bias in data, algorithms, and deployment strategies. Ensuring equal access to the benefits of AI and preventing the exacerbation of existing inequalities.\n",
       "    *   **Application:**  Algorithms used for loan applications, hiring processes, and criminal justice should be rigorously tested for bias and adjusted to ensure fairness. Diverse datasets and algorithm development teams should be employed to minimize unintentional biases.\n",
       "\n",
       "3.  **Transparency and Explainability (Interpretability):** AI decision-making processes should be as transparent and explainable as possible, allowing users to understand how conclusions are reached.\n",
       "    *   **Focus:** Creating AI systems that can justify their decisions and provide insights into the reasoning behind them. Making information about data sources, algorithms, and model limitations accessible to relevant stakeholders.\n",
       "    *   **Application:** In critical domains like healthcare and finance, AI systems should provide clear explanations for their recommendations, enabling human oversight and accountability. Using techniques like SHAP values or LIME to highlight the factors influencing AI decisions.\n",
       "\n",
       "4.  **Accountability and Responsibility:** Individuals and organizations that develop and deploy AI systems must be held accountable for their impacts.\n",
       "    *   **Focus:** Establishing clear lines of responsibility for AI system failures or unintended consequences. Developing mechanisms for redress and remediation when harm occurs.\n",
       "    *   **Application:**  Companies developing autonomous vehicles should be held accountable for accidents caused by their technology. Independent audits and certifications should be required for AI systems used in high-stakes decision-making.\n",
       "\n",
       "5.  **Privacy and Data Security:** AI systems should respect individual privacy and ensure the security of personal data.\n",
       "    *   **Focus:** Implementing robust data protection measures, including anonymization, encryption, and access controls.  Adhering to privacy regulations (e.g., GDPR, CCPA) and obtaining informed consent for data collection and usage.\n",
       "    *   **Application:**  Using federated learning to train AI models on decentralized data without compromising individual privacy. Implementing differential privacy techniques to protect sensitive information in datasets.\n",
       "\n",
       "6.  **Sustainability and Environmental Responsibility:**  AI development and deployment should be environmentally sustainable, minimizing energy consumption and resource usage.\n",
       "    *   **Focus:**  Promoting energy-efficient AI algorithms and hardware.  Minimizing the carbon footprint of AI training and deployment.  Using AI to address environmental challenges.\n",
       "    *   **Application:**  Developing AI algorithms that require less computational power.  Optimizing data center energy consumption.  Using AI to improve energy efficiency in industries like transportation and manufacturing.\n",
       "\n",
       "7.  **Robustness and Safety:** AI systems should be robust against adversarial attacks and designed to operate safely under a wide range of conditions.\n",
       "    *   **Focus:**  Developing AI systems that are resilient to malicious inputs and unexpected scenarios.  Implementing safety mechanisms to prevent unintended or harmful behaviors.\n",
       "    *   **Application:**  Training AI systems to detect and defend against adversarial attacks.  Designing fail-safe mechanisms for autonomous systems.  Conducting rigorous testing and validation to ensure safety.\n",
       "\n",
       "**II. Implementation Strategies:**\n",
       "\n",
       "1.  **Multi-Stakeholder Engagement:** Develop the framework through inclusive dialogue with diverse stakeholders: AI researchers, ethicists, policymakers, industry representatives, civil society organizations, and the general public.\n",
       "    *   **Why:**  Ensures the framework reflects a wide range of perspectives and addresses societal concerns effectively.\n",
       "    *   **How:**  Conduct public consultations, workshops, and online forums to gather feedback on the principles and implementation strategies.\n",
       "\n",
       "2.  **Contextual Adaptation:**  Recognize that ethical considerations vary across different applications and cultural contexts. Adapt the framework to address specific challenges and values.\n",
       "    *   **Why:**  A one-size-fits-all approach will not work. Ethical norms and societal priorities differ significantly across cultures and domains.\n",
       "    *   **How:**  Develop guidelines and best practices tailored to specific industries and regions. Encourage local communities to adapt the framework to their own cultural values.\n",
       "\n",
       "3.  **Education and Training:**  Provide comprehensive education and training on AI ethics for developers, policymakers, and the general public.\n",
       "    *   **Why:**  Raises awareness of ethical issues and equips individuals with the knowledge and skills to develop and deploy AI responsibly.\n",
       "    *   **How:**  Integrate AI ethics into computer science curricula. Offer online courses and workshops for professionals. Develop public awareness campaigns to promote responsible AI use.\n",
       "\n",
       "4.  **Standards and Certification:**  Establish standards and certification programs for AI systems to ensure compliance with ethical principles.\n",
       "    *   **Why:**  Provides a mechanism for verifying that AI systems meet ethical requirements and fosters public trust.\n",
       "    *   **How:**  Develop industry-specific standards for AI ethics. Establish independent certification bodies to assess AI systems. Encourage companies to adopt ethical AI certifications.\n",
       "\n",
       "5.  **Algorithmic Auditing:**  Implement regular audits of AI algorithms to detect and mitigate bias and ensure fairness.\n",
       "    *   **Why:**  Identifies and corrects unintended biases in AI systems. Provides transparency and accountability for algorithmic decision-making.\n",
       "    *   **How:**  Employ independent auditors to evaluate AI algorithms. Develop tools and techniques for detecting and measuring bias. Require disclosure of audit results to stakeholders.\n",
       "\n",
       "6.  **Regulatory Oversight:**  Establish regulatory frameworks to govern the development and deployment of AI systems, particularly in high-risk areas.\n",
       "    *   **Why:**  Provides a legal basis for enforcing ethical principles and holding accountable those who violate them.\n",
       "    *   **How:**  Develop regulations addressing specific risks associated with AI, such as bias in hiring or discrimination in lending. Establish enforcement mechanisms and penalties for non-compliance.\n",
       "\n",
       "7.  **International Collaboration:**  Foster international collaboration to develop and promote a global framework for AI ethics.\n",
       "    *   **Why:**  Addresses the global implications of AI and ensures that ethical principles are applied consistently across borders.\n",
       "    *   **How:**  Establish international forums for dialogue and collaboration on AI ethics. Develop shared standards and guidelines for responsible AI development. Promote cross-cultural understanding of ethical values.\n",
       "\n",
       "8.  **Continuous Monitoring and Evaluation:**  Continuously monitor and evaluate the impact of AI systems and update the framework as needed.\n",
       "    *   **Why:**  AI is a rapidly evolving field, and ethical considerations will change over time. The framework must be adaptable to new challenges and opportunities.\n",
       "    *   **How:**  Track the social, economic, and environmental impacts of AI. Conduct regular reviews of the framework to identify areas for improvement. Incorporate feedback from stakeholders to ensure the framework remains relevant and effective.\n",
       "\n",
       "**Key Considerations for Success:**\n",
       "\n",
       "*   **Dynamic Framework:**  The ethical framework must be a living document, continuously evolving to reflect technological advancements, societal shifts, and emerging ethical concerns.\n",
       "*   **Practical Guidance:** The framework needs to provide concrete guidance and actionable steps for developers, policymakers, and users to implement ethical principles in their work.\n",
       "*   **Enforcement Mechanisms:** Without enforcement mechanisms, the framework will lack teeth. Regulations, standards, and certification programs are essential for holding individuals and organizations accountable.\n",
       "*   **Global Inclusivity:** The framework must be inclusive of diverse cultural perspectives and values. It should not be imposed by one region or culture on others.\n",
       "\n",
       "By prioritizing these principles and implementation strategies, we can strive to create an ethical framework that promotes the responsible development and deployment of AI for the benefit of all humanity.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, so I need to design a new ethical framework for AI. Let me start by thinking about what principles are important. I've heard terms like fairness, transparency, accountability, privacy... Maybe those are key. But how do I make sure they work across different cultures and applications?\n",
       "\n",
       "First, maybe I should outline the core principles. Let me brainstorm. Fairness and non-discrimination seem essential because AI can perpetuate biases. Then transparency, so people understand how AI makes decisions. Accountability is another one—someone should be responsible if things go wrong. Privacy and data protection are important too, especially with all the data AI systems use. Also, maybe something about safety and security, ensuring AI doesn't cause harm. And perhaps respect for human autonomy, letting people make their own decisions even when AI is involved.\n",
       "\n",
       "Wait, but how do these principles apply across different cultures? For example, what's considered fair in one culture might not be in another. Or privacy expectations vary. So the framework needs to be flexible enough to adapt to cultural contexts. But also have some universal standards. Maybe universal principles grounded in human rights, and then culturally specific implementations?\n",
       "\n",
       "Implementation is another challenge. How do you ensure that these principles are actually followed? Maybe through regulations, audits, certification processes. Involving diverse stakeholders in the design and oversight. Also, technical measures like algorithms that are auditable, explainable AI. Maybe requiring impact assessments before deploying AI systems. Education and training for developers to be aware of ethical issues. Collaboration between different sectors—tech companies, governments, civil society.\n",
       "\n",
       "Wait, but there's also the issue of enforcement. If a principle is not followed, what are the consequences? Maybe legal frameworks, penalties, but that depends on the jurisdiction. Also, international cooperation might be necessary to set global standards, but respecting local laws.\n",
       "\n",
       "Hmm, maybe I should structure this into principles and then implementation strategies. Let me try listing the principles again with more detail:\n",
       "\n",
       "1. **Human Autonomy and Dignity**: AI should support human decision-making, not override it. Respect for individual rights and human dignity.\n",
       "\n",
       "2. **Fairness and Non-Discrimination**: AI systems must not discriminate based on race, gender, etc. They should be tested for bias and ensure equitable outcomes.\n",
       "\n",
       "3. **Transparency and Explainability**: AI systems should be transparent in their operations. Users should be able to understand how decisions are made, especially in critical areas like healthcare or criminal justice.\n",
       "\n",
       "4. **Accountability**: Clear lines of responsibility for AI decisions. Organizations must be accountable for harms caused by AI systems.\n",
       "\n",
       "5. **Privacy and Data Protection**: Strong safeguards for personal data. Compliance with data protection laws and ensuring minimal data collection.\n",
       "\n",
       "6. **Safety and Security**: AI systems should be secure and prevent harm, both to individuals and society.\n",
       "\n",
       "7. **Sustainability and Environmental Responsibility**: Considering the environmental impact of AI development and deployment.\n",
       "\n",
       "8. **Cultural Sensitivity and Inclusivity**: AI should respect cultural diversity and be inclusive, avoiding cultural insensitivity.\n",
       "\n",
       "Now, for implementation strategies. Maybe:\n",
       "\n",
       "- **Multistakeholder Governance**: Involving a variety of stakeholders in the creation and oversight of AI systems.\n",
       "\n",
       "- **Ethical Impact Assessments**: Mandatory assessments before deployment to evaluate ethical implications.\n",
       "\n",
       "- **Technical Standards and Best Practices**: Developing industry-wide standards for ethical AI, like explainable AI techniques, bias mitigation algorithms.\n",
       "\n",
       "- **Education and Training**: Ensuring that developers and users are trained in ethical AI practices.\n",
       "\n",
       "- **Legal and Regulatory Frameworks**: Laws that enforce these principles, with penalties for non-compliance.\n",
       "\n",
       "- **Cultural Adaptation Mechanisms**: Frameworks that allow for local customization while adhering to core ethical principles.\n",
       "\n",
       "- **Monitoring and Auditing**: Regular audits of AI systems to ensure compliance and effectiveness.\n",
       "\n",
       "- **Public Engagement and Feedback**: Involving the public in the design process and allowing feedback to improve systems.\n",
       "\n",
       "But how do I make sure that these principles are applied across diverse applications? For example, in healthcare vs. finance vs. law enforcement. Each might have different needs and risks. Maybe the framework would need to have adaptable guidelines that can be tailored to specific sectors, with core principles that remain consistent.\n",
       "\n",
       "Also, considering the global aspect, maybe a tiered approach where universal principles are applied, and then local regulations build upon them. For instance, the European Union has strict data protection laws, while other regions might have different priorities. The framework would need to respect that while promoting international cooperation.\n",
       "\n",
       "Another point is the use of AI in different cultural contexts. For example, in some cultures, transparency might be less emphasized due to different norms around privacy or collective decision-making. The framework would need to balance universal ethical standards with cultural relativism.\n",
       "\n",
       "I should also think about the role of technology itself. For example, tools that help detect bias, ensure transparency, or manage data securely. Maybe integrating ethical design into the AI development lifecycle from the start, like through ethical AI by design principles.\n",
       "\n",
       "In summary, the key principles would be the eight I listed, and implementation would involve a mix of governance, legal frameworks, technical measures, education, and cultural adaptation. Ensuring effectiveness requires ongoing monitoring, stakeholder involvement, and flexibility to adapt to different contexts while maintaining core ethical standards.\n",
       "</think>\n",
       "\n",
       "Designing a comprehensive ethical framework for AI requires balancing universal principles with adaptability to diverse cultural, technical, and societal contexts. Below is a structured approach, detailing key principles and implementation strategies to ensure ethical AI across applications and cultures.\n",
       "\n",
       "---\n",
       "\n",
       "### **Key Ethical Principles for AI**\n",
       "\n",
       "1. **Human Autonomy and Dignity**  \n",
       "   - **Core Ethic**: AI must enhance human agency, avoid coercion, and uphold dignity.  \n",
       "   - **Application**: Ensure systems allow for informed human choice (e.g., explainable recommendations, opt-in features).\n",
       "\n",
       "2. **Fairness, Equity, and Non-Discrimination**  \n",
       "   - **Core Ethic**: Eliminate bias and ensure equitable outcomes across all groups.  \n",
       "   - **Application**: Use bias-mitigation algorithms, inclusive datasets, and audits for fairness in hiring, healthcare, and law enforcement.\n",
       "\n",
       "3. **Transparency and Explainability**  \n",
       "   - **Core Ethic**: AI decision-making processes must be understandable to users and stakeholders.  \n",
       "   - **Application**: Implement explainable AI (XAI) techniques, provide user-facing documentation, and ensure interpretability in high-stakes domains (e.g., finance, criminal justice).\n",
       "\n",
       "4. **Accountability and Remediation**  \n",
       "   - **Core Ethic**: Clear responsibility for AI harms, with mechanisms for redress.  \n",
       "   - **Application**: Assign legal liability to developers/deployers, establish ombudsman roles, and mandate reporting of AI-caused harms.\n",
       "\n",
       "5. **Privacy and Data Protection**  \n",
       "   - **Core Ethic**: Safeguard personal data and respect user privacy.  \n",
       "   - **Application**: Comply with global data laws (e.g., GDPR, CCPA), use differential privacy, and minimize data collection.\n",
       "\n",
       "6. **Safety and Security**  \n",
       "   - **Core Ethic**: Prevent harm through robust security measures.  \n",
       "   - **Application**: Stress-test systems against adversarial attacks, ensure cybersecurity, and address risks like AI-driven disinformation.\n",
       "\n",
       "7. **Cultural Sensitivity and Inclusivity**  \n",
       "   - **Core Ethic**: Respect cultural diversity and avoid insensitivity.  \n",
       "   - **Application**: Involve local communities in design, adapt language/models to cultural norms, and avoid ethnocentric assumptions.\n",
       "\n",
       "8. **Sustainability and Environmental Responsibility**  \n",
       "   - **Core Ethic**: Minimize ecological impact.  \n",
       "   - **Application**: Optimize energy efficiency in AI training, promote green computing, and assess carbon footprints.\n",
       "\n",
       "---\n",
       "\n",
       "### **Implementation Strategies**\n",
       "\n",
       "1. **Multistakeholder Governance**  \n",
       "   - **Collaboration**: Include governments, civil society, industry, academia, and affected communities in policy-making and oversight.  \n",
       "   - **Example**: Global AI ethics councils or sector-specific boards (e.g., healthcare, finance).\n",
       "\n",
       "2. **Ethical Impact Assessments (EIAs)**  \n",
       "   - **Process**: Mandate EIAs for high-risk AI systems to evaluate risks to human rights, equity, and environment.  \n",
       "   - **Tools**: Use standardized templates to assess bias, privacy risks, and cultural impacts.\n",
       "\n",
       "3. **Technical Standards and Auditing**  \n",
       "   - **Standards**: Develop open-source tools for bias detection, transparency, and compliance (e.g., fairness metrics, auditing frameworks).  \n",
       "   - **Audits**: Require third-party audits for AI systems before deployment and during use.\n",
       "\n",
       "4. **Legal and Regulatory Frameworks**  \n",
       "   - **Global-Local Balance**: Establish universal principles (e.g., through international treaties) while allowing regional adaptations.  \n",
       "   - **Enforcement**: Impose penalties for non-compliance, with incentives for ethical AI (e.g., tax breaks, certifications).\n",
       "\n",
       "5. **Education and Training**  \n",
       "   - **Training Programs**: Integrate ethics into AI curricula for developers, and provide ongoing training for users (e.g., \"AI literacy\" campaigns).  \n",
       "   - **Incentives**: Certify professionals in ethical AI practices.\n",
       "\n",
       "6. **Cultural Adaptation Mechanisms**  \n",
       "   - **Localization**: Allow flexible application of principles (e.g., varying definitions of privacy in different cultures).  \n",
       "   - **Community Engagement**: Collaborate with local leaders to co-design AI systems that align with cultural values.\n",
       "\n",
       "7. **Public Engagement and Feedback**  \n",
       "   - **Participatory Design**: Involve communities in AI development, especially marginalized groups.  \n",
       "   - **Feedback Loops**: Create platforms for public input and continuous improvement of AI systems.\n",
       "\n",
       "8. **Monitoring and Continuous Improvement**  \n",
       "   - **Real-Time Monitoring**: Deploy tools to track AI performance, bias, and unintended consequences.  \n",
       "   - **Updates**: Require regular updates to systems based on feedback and evolving ethical standards.\n",
       "\n",
       "---\n",
       "\n",
       "### **Ensuring Cross-Cultural and Cross-Application Effectiveness**\n",
       "\n",
       "- **Modular Guidelines**: Develop principles that are universally applicable but allow customization (e.g., sector-specific rules for healthcare vs. entertainment).  \n",
       "- **Case Studies and Best Practices**: Share successful examples globally to guide local implementation.  \n",
       "- **International Collaboration**: Harmonize standards through organizations like the UN or OECD, while respecting local laws.  \n",
       "- **Ethical AI by Design**: Embed ethics into the AI lifecycle (requirements, development, deployment, and decommissioning).\n",
       "\n",
       "---\n",
       "\n",
       "### **Conclusion**\n",
       "\n",
       "A robust AI ethical framework must be both aspirational and pragmatic, rooted in universal human rights while adaptable to cultural and technical contexts. Success relies on a combination of governance, technology, education, and ongoing engagement. By prioritizing these principles and strategies, AI can be developed to benefit humanity equitably and responsibly."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"qwen3:14b\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4o-mini', 'gemini-2.0-flash', 'llama3.2', 'qwen3:14b']\n",
      "['Designing a new ethical framework for artificial intelligence (AI) is a '\n",
      " 'complex task that requires careful consideration of various factors, '\n",
      " 'including technological capabilities, societal implications, and cultural '\n",
      " 'nuances. Here are the key principles I would prioritize, along with '\n",
      " 'strategies for effective implementation:\\n'\n",
      " '\\n'\n",
      " '### Key Principles\\n'\n",
      " '\\n'\n",
      " '1. **Fairness and Non-Discrimination**:\\n'\n",
      " '   - AI systems should be designed to avoid bias and discrimination against '\n",
      " 'individuals based on race, gender, ethnicity, socio-economic status, or '\n",
      " 'other protected characteristics.\\n'\n",
      " '  \\n'\n",
      " '2. **Transparency and Explainability**:\\n'\n",
      " '   - AI decision-making processes should be transparent and understandable, '\n",
      " 'enabling users to comprehend how decisions are made and the data involved.\\n'\n",
      " '\\n'\n",
      " '3. **Accountability**:\\n'\n",
      " '   - Clear lines of accountability must be established for decisions made by '\n",
      " 'AI systems, including responsibilities assigned to developers, operators, '\n",
      " 'and organizations deploying AI technologies.\\n'\n",
      " '\\n'\n",
      " '4. **Privacy and Data Protection**:\\n'\n",
      " \"   - Individuals' privacy should be respected, ensuring that personal data \"\n",
      " 'is collected, stored, and processed with consent and in compliance with '\n",
      " 'applicable regulations.\\n'\n",
      " '\\n'\n",
      " '5. **Safety and Security**:\\n'\n",
      " '   - AI systems should be developed with a focus on minimizing potential '\n",
      " 'harms or risks, both physical and psychological, ensuring robust security '\n",
      " 'measures against misuse.\\n'\n",
      " '\\n'\n",
      " '6. **Human-Centric Design**:\\n'\n",
      " '   - AI should augment human capabilities and rights, placing human '\n",
      " 'well-being at the core of its design and deployment.\\n'\n",
      " '\\n'\n",
      " '7. **Sustainability**:\\n'\n",
      " '   - The environmental impact of AI systems should be considered, '\n",
      " 'encouraging energy-efficient practices and promoting sustainability in AI '\n",
      " 'development.\\n'\n",
      " '\\n'\n",
      " '8. **Inclusivity**:\\n'\n",
      " '   - Stakeholders from various backgrounds—including marginalized and '\n",
      " 'vulnerable communities—should be included in the design and deployment '\n",
      " 'processes to ensure diverse perspectives are considered.\\n'\n",
      " '\\n'\n",
      " '9. **Respect for Autonomy**:\\n'\n",
      " '   - AI applications should respect human autonomy and dignity, allowing '\n",
      " 'individuals to make informed choices without undue influence.\\n'\n",
      " '\\n'\n",
      " '10. **Adaptability and Continuous Learning**:\\n'\n",
      " '    - The framework should be dynamic, allowing for adaptation as technology '\n",
      " 'evolves and societal values change.\\n'\n",
      " '\\n'\n",
      " '### Implementation Strategies\\n'\n",
      " '\\n'\n",
      " '1. **Establishing Regulatory Bodies**:\\n'\n",
      " '   - Create independent regulatory bodies that can oversee AI development '\n",
      " 'and enforce compliance with the ethical framework. These bodies should '\n",
      " 'include diverse representation from different cultural and societal '\n",
      " 'backgrounds.\\n'\n",
      " '\\n'\n",
      " '2. **Global Collaboration**:\\n'\n",
      " '   - Promote international cooperation and dialogue to align ethical '\n",
      " 'standards internationally while being sensitive to localized cultural norms. '\n",
      " 'This can include workshops, conferences, and collaborative research.\\n'\n",
      " '\\n'\n",
      " '3. **Education and Training**:\\n'\n",
      " '   - Integrate ethical training into the curriculum for AI developers, '\n",
      " 'engineers, and users, ensuring they understand the implications of their '\n",
      " 'work and are equipped to uphold these principles.\\n'\n",
      " '\\n'\n",
      " '4. **Stakeholder Engagement**:\\n'\n",
      " '   - Engage a wide range of stakeholders—including civil society, industry '\n",
      " 'leaders, policymakers, and affected communities—in the development of AI to '\n",
      " 'gather input and gain diverse insights.\\n'\n",
      " '\\n'\n",
      " '5. **Establishing best practices and guidelines**:\\n'\n",
      " '   - Develop and disseminate best practices for implementing ethical '\n",
      " 'principles in various AI applications across sectors, tailoring them to '\n",
      " 'specific needs and cultural contexts.\\n'\n",
      " '\\n'\n",
      " '6. **Monitoring and Auditing**:\\n'\n",
      " '   - Implement regular audits and assessments of AI systems to evaluate '\n",
      " 'compliance with ethical standards, involving third-party reviewers to ensure '\n",
      " 'objectivity.\\n'\n",
      " '\\n'\n",
      " '7. **Feedback Mechanisms**:\\n'\n",
      " '   - Create channels for users and affected communities to provide feedback '\n",
      " 'on AI systems, enabling ongoing dialogue about ethics and performance.\\n'\n",
      " '\\n'\n",
      " '8. **Funding and Support for Ethical Innovation**:\\n'\n",
      " '   - Encourage funding for research and development of AI technologies that '\n",
      " 'prioritize ethical considerations and social good, including grants and '\n",
      " 'incentives for organizations dedicated to ethical AI.\\n'\n",
      " '\\n'\n",
      " '9. **Cultural Sensitivity Initiatives**:\\n'\n",
      " '   - Develop resources and guidelines that incorporate an understanding of '\n",
      " 'cultural differences in the adoption and perception of AI, ensuring '\n",
      " 'principles respect and adapt to local customs and values.\\n'\n",
      " '\\n'\n",
      " '10. **Public Awareness Campaigns**:\\n'\n",
      " '    - Conduct public awareness campaigns to educate communities about AI '\n",
      " 'technologies and their implications, fostering informed public discourse and '\n",
      " 'engagement.\\n'\n",
      " '\\n'\n",
      " 'By prioritizing these principles and strategically implementing them through '\n",
      " 'diverse channels, we can develop a robust ethical framework for AI that is '\n",
      " 'adaptable, inclusive, and respectful of different cultures and contexts.',\n",
      " 'Designing a new ethical framework for AI requires a multi-faceted approach '\n",
      " 'that prioritizes both core principles and their effective implementation '\n",
      " \"across diverse contexts. Here's my proposed framework:\\n\"\n",
      " '\\n'\n",
      " '**I. Core Principles:**\\n'\n",
      " '\\n'\n",
      " '1.  **Human-Centricity & Well-being:**  AI should prioritize human '\n",
      " 'well-being, dignity, and rights.\\n'\n",
      " '    *   **Focus:** AI systems should be designed and deployed in ways that '\n",
      " 'improve human lives, promote equity, and avoid causing harm. This includes '\n",
      " 'physical, psychological, economic, and social well-being.\\n'\n",
      " '    *   **Application:**  AI-driven healthcare should improve patient '\n",
      " 'outcomes and access. AI-powered education should personalize learning and '\n",
      " 'reduce educational disparities. AI-based security systems should protect '\n",
      " 'individuals without infringing on their civil liberties.\\n'\n",
      " '\\n'\n",
      " '2.  **Fairness, Equity, and Non-Discrimination:** AI systems must be fair '\n",
      " 'and equitable, avoiding discriminatory outcomes based on protected '\n",
      " 'characteristics (e.g., race, gender, religion, sexual orientation, '\n",
      " 'disability).\\n'\n",
      " '    *   **Focus:** Proactive identification and mitigation of bias in data, '\n",
      " 'algorithms, and deployment strategies. Ensuring equal access to the benefits '\n",
      " 'of AI and preventing the exacerbation of existing inequalities.\\n'\n",
      " '    *   **Application:**  Algorithms used for loan applications, hiring '\n",
      " 'processes, and criminal justice should be rigorously tested for bias and '\n",
      " 'adjusted to ensure fairness. Diverse datasets and algorithm development '\n",
      " 'teams should be employed to minimize unintentional biases.\\n'\n",
      " '\\n'\n",
      " '3.  **Transparency and Explainability (Interpretability):** AI '\n",
      " 'decision-making processes should be as transparent and explainable as '\n",
      " 'possible, allowing users to understand how conclusions are reached.\\n'\n",
      " '    *   **Focus:** Creating AI systems that can justify their decisions and '\n",
      " 'provide insights into the reasoning behind them. Making information about '\n",
      " 'data sources, algorithms, and model limitations accessible to relevant '\n",
      " 'stakeholders.\\n'\n",
      " '    *   **Application:** In critical domains like healthcare and finance, AI '\n",
      " 'systems should provide clear explanations for their recommendations, '\n",
      " 'enabling human oversight and accountability. Using techniques like SHAP '\n",
      " 'values or LIME to highlight the factors influencing AI decisions.\\n'\n",
      " '\\n'\n",
      " '4.  **Accountability and Responsibility:** Individuals and organizations '\n",
      " 'that develop and deploy AI systems must be held accountable for their '\n",
      " 'impacts.\\n'\n",
      " '    *   **Focus:** Establishing clear lines of responsibility for AI system '\n",
      " 'failures or unintended consequences. Developing mechanisms for redress and '\n",
      " 'remediation when harm occurs.\\n'\n",
      " '    *   **Application:**  Companies developing autonomous vehicles should be '\n",
      " 'held accountable for accidents caused by their technology. Independent '\n",
      " 'audits and certifications should be required for AI systems used in '\n",
      " 'high-stakes decision-making.\\n'\n",
      " '\\n'\n",
      " '5.  **Privacy and Data Security:** AI systems should respect individual '\n",
      " 'privacy and ensure the security of personal data.\\n'\n",
      " '    *   **Focus:** Implementing robust data protection measures, including '\n",
      " 'anonymization, encryption, and access controls.  Adhering to privacy '\n",
      " 'regulations (e.g., GDPR, CCPA) and obtaining informed consent for data '\n",
      " 'collection and usage.\\n'\n",
      " '    *   **Application:**  Using federated learning to train AI models on '\n",
      " 'decentralized data without compromising individual privacy. Implementing '\n",
      " 'differential privacy techniques to protect sensitive information in '\n",
      " 'datasets.\\n'\n",
      " '\\n'\n",
      " '6.  **Sustainability and Environmental Responsibility:**  AI development and '\n",
      " 'deployment should be environmentally sustainable, minimizing energy '\n",
      " 'consumption and resource usage.\\n'\n",
      " '    *   **Focus:**  Promoting energy-efficient AI algorithms and hardware.  '\n",
      " 'Minimizing the carbon footprint of AI training and deployment.  Using AI to '\n",
      " 'address environmental challenges.\\n'\n",
      " '    *   **Application:**  Developing AI algorithms that require less '\n",
      " 'computational power.  Optimizing data center energy consumption.  Using AI '\n",
      " 'to improve energy efficiency in industries like transportation and '\n",
      " 'manufacturing.\\n'\n",
      " '\\n'\n",
      " '7.  **Robustness and Safety:** AI systems should be robust against '\n",
      " 'adversarial attacks and designed to operate safely under a wide range of '\n",
      " 'conditions.\\n'\n",
      " '    *   **Focus:**  Developing AI systems that are resilient to malicious '\n",
      " 'inputs and unexpected scenarios.  Implementing safety mechanisms to prevent '\n",
      " 'unintended or harmful behaviors.\\n'\n",
      " '    *   **Application:**  Training AI systems to detect and defend against '\n",
      " 'adversarial attacks.  Designing fail-safe mechanisms for autonomous '\n",
      " 'systems.  Conducting rigorous testing and validation to ensure safety.\\n'\n",
      " '\\n'\n",
      " '**II. Implementation Strategies:**\\n'\n",
      " '\\n'\n",
      " '1.  **Multi-Stakeholder Engagement:** Develop the framework through '\n",
      " 'inclusive dialogue with diverse stakeholders: AI researchers, ethicists, '\n",
      " 'policymakers, industry representatives, civil society organizations, and the '\n",
      " 'general public.\\n'\n",
      " '    *   **Why:**  Ensures the framework reflects a wide range of '\n",
      " 'perspectives and addresses societal concerns effectively.\\n'\n",
      " '    *   **How:**  Conduct public consultations, workshops, and online forums '\n",
      " 'to gather feedback on the principles and implementation strategies.\\n'\n",
      " '\\n'\n",
      " '2.  **Contextual Adaptation:**  Recognize that ethical considerations vary '\n",
      " 'across different applications and cultural contexts. Adapt the framework to '\n",
      " 'address specific challenges and values.\\n'\n",
      " '    *   **Why:**  A one-size-fits-all approach will not work. Ethical norms '\n",
      " 'and societal priorities differ significantly across cultures and domains.\\n'\n",
      " '    *   **How:**  Develop guidelines and best practices tailored to specific '\n",
      " 'industries and regions. Encourage local communities to adapt the framework '\n",
      " 'to their own cultural values.\\n'\n",
      " '\\n'\n",
      " '3.  **Education and Training:**  Provide comprehensive education and '\n",
      " 'training on AI ethics for developers, policymakers, and the general public.\\n'\n",
      " '    *   **Why:**  Raises awareness of ethical issues and equips individuals '\n",
      " 'with the knowledge and skills to develop and deploy AI responsibly.\\n'\n",
      " '    *   **How:**  Integrate AI ethics into computer science curricula. Offer '\n",
      " 'online courses and workshops for professionals. Develop public awareness '\n",
      " 'campaigns to promote responsible AI use.\\n'\n",
      " '\\n'\n",
      " '4.  **Standards and Certification:**  Establish standards and certification '\n",
      " 'programs for AI systems to ensure compliance with ethical principles.\\n'\n",
      " '    *   **Why:**  Provides a mechanism for verifying that AI systems meet '\n",
      " 'ethical requirements and fosters public trust.\\n'\n",
      " '    *   **How:**  Develop industry-specific standards for AI ethics. '\n",
      " 'Establish independent certification bodies to assess AI systems. Encourage '\n",
      " 'companies to adopt ethical AI certifications.\\n'\n",
      " '\\n'\n",
      " '5.  **Algorithmic Auditing:**  Implement regular audits of AI algorithms to '\n",
      " 'detect and mitigate bias and ensure fairness.\\n'\n",
      " '    *   **Why:**  Identifies and corrects unintended biases in AI systems. '\n",
      " 'Provides transparency and accountability for algorithmic decision-making.\\n'\n",
      " '    *   **How:**  Employ independent auditors to evaluate AI algorithms. '\n",
      " 'Develop tools and techniques for detecting and measuring bias. Require '\n",
      " 'disclosure of audit results to stakeholders.\\n'\n",
      " '\\n'\n",
      " '6.  **Regulatory Oversight:**  Establish regulatory frameworks to govern the '\n",
      " 'development and deployment of AI systems, particularly in high-risk areas.\\n'\n",
      " '    *   **Why:**  Provides a legal basis for enforcing ethical principles '\n",
      " 'and holding accountable those who violate them.\\n'\n",
      " '    *   **How:**  Develop regulations addressing specific risks associated '\n",
      " 'with AI, such as bias in hiring or discrimination in lending. Establish '\n",
      " 'enforcement mechanisms and penalties for non-compliance.\\n'\n",
      " '\\n'\n",
      " '7.  **International Collaboration:**  Foster international collaboration to '\n",
      " 'develop and promote a global framework for AI ethics.\\n'\n",
      " '    *   **Why:**  Addresses the global implications of AI and ensures that '\n",
      " 'ethical principles are applied consistently across borders.\\n'\n",
      " '    *   **How:**  Establish international forums for dialogue and '\n",
      " 'collaboration on AI ethics. Develop shared standards and guidelines for '\n",
      " 'responsible AI development. Promote cross-cultural understanding of ethical '\n",
      " 'values.\\n'\n",
      " '\\n'\n",
      " '8.  **Continuous Monitoring and Evaluation:**  Continuously monitor and '\n",
      " 'evaluate the impact of AI systems and update the framework as needed.\\n'\n",
      " '    *   **Why:**  AI is a rapidly evolving field, and ethical considerations '\n",
      " 'will change over time. The framework must be adaptable to new challenges and '\n",
      " 'opportunities.\\n'\n",
      " '    *   **How:**  Track the social, economic, and environmental impacts of '\n",
      " 'AI. Conduct regular reviews of the framework to identify areas for '\n",
      " 'improvement. Incorporate feedback from stakeholders to ensure the framework '\n",
      " 'remains relevant and effective.\\n'\n",
      " '\\n'\n",
      " '**Key Considerations for Success:**\\n'\n",
      " '\\n'\n",
      " '*   **Dynamic Framework:**  The ethical framework must be a living document, '\n",
      " 'continuously evolving to reflect technological advancements, societal '\n",
      " 'shifts, and emerging ethical concerns.\\n'\n",
      " '*   **Practical Guidance:** The framework needs to provide concrete guidance '\n",
      " 'and actionable steps for developers, policymakers, and users to implement '\n",
      " 'ethical principles in their work.\\n'\n",
      " '*   **Enforcement Mechanisms:** Without enforcement mechanisms, the '\n",
      " 'framework will lack teeth. Regulations, standards, and certification '\n",
      " 'programs are essential for holding individuals and organizations '\n",
      " 'accountable.\\n'\n",
      " '*   **Global Inclusivity:** The framework must be inclusive of diverse '\n",
      " 'cultural perspectives and values. It should not be imposed by one region or '\n",
      " 'culture on others.\\n'\n",
      " '\\n'\n",
      " 'By prioritizing these principles and implementation strategies, we can '\n",
      " 'strive to create an ethical framework that promotes the responsible '\n",
      " 'development and deployment of AI for the benefit of all humanity.\\n',\n",
      " 'As part of designing a new ethical framework for artificial intelligence '\n",
      " '(AI), I would prioritize the following key principles:\\n'\n",
      " '\\n'\n",
      " '1. **Transparency and Explainability**: AI systems should be designed to '\n",
      " 'provide clear understandings about their decision-making processes, '\n",
      " 'algorithms, and potential biases. This ensures accountability and trust in '\n",
      " 'AI-driven decisions.\\n'\n",
      " '\\n'\n",
      " '2. **Fairness and Non-Discrimination**: AI systems should avoid perpetuating '\n",
      " 'existing social imbalances based on factors like race, gender, age, '\n",
      " 'religion, ethnicity, or socioeconomic status. They should ensure equal '\n",
      " 'quality of services and opportunities for all individuals.\\n'\n",
      " '\\n'\n",
      " '3. **Respect for Digital Rights**: Organizations using AI must collect '\n",
      " 'personal data responsibly, respect data autonomy and consent, prevent '\n",
      " 'misuse, and disclose clear usage terms to avoid unauthorized tracking or '\n",
      " 'exploitation.\\n'\n",
      " '\\n'\n",
      " '4. **Accountability and Responsibility**: Human developers must be clearly '\n",
      " 'linked with their AI creations when they are made public. As well as there '\n",
      " 'being oversight processes put into place that enable rapid resolution if '\n",
      " 'issues arise.\\n'\n",
      " '\\n'\n",
      " '5. **Autonomy and User Choice**: Users have the ability to control AI-driven '\n",
      " 'interactions, including setting limits on tracking and privacy preferences.\\n'\n",
      " '\\n'\n",
      " '6.  **Safety and Security**: The most important priority is developing '\n",
      " 'artificial intelligence systems which do not pose a severe threat to human '\n",
      " 'life, either intentionally or unintentionally, even if they are created for '\n",
      " 'positive reasons.',\n",
      " '<think>\\n'\n",
      " 'Okay, so I need to design a new ethical framework for AI. Let me start by '\n",
      " \"thinking about what principles are important. I've heard terms like \"\n",
      " 'fairness, transparency, accountability, privacy... Maybe those are key. But '\n",
      " 'how do I make sure they work across different cultures and applications?\\n'\n",
      " '\\n'\n",
      " 'First, maybe I should outline the core principles. Let me brainstorm. '\n",
      " 'Fairness and non-discrimination seem essential because AI can perpetuate '\n",
      " 'biases. Then transparency, so people understand how AI makes decisions. '\n",
      " 'Accountability is another one—someone should be responsible if things go '\n",
      " 'wrong. Privacy and data protection are important too, especially with all '\n",
      " 'the data AI systems use. Also, maybe something about safety and security, '\n",
      " \"ensuring AI doesn't cause harm. And perhaps respect for human autonomy, \"\n",
      " 'letting people make their own decisions even when AI is involved.\\n'\n",
      " '\\n'\n",
      " 'Wait, but how do these principles apply across different cultures? For '\n",
      " \"example, what's considered fair in one culture might not be in another. Or \"\n",
      " 'privacy expectations vary. So the framework needs to be flexible enough to '\n",
      " 'adapt to cultural contexts. But also have some universal standards. Maybe '\n",
      " 'universal principles grounded in human rights, and then culturally specific '\n",
      " 'implementations?\\n'\n",
      " '\\n'\n",
      " 'Implementation is another challenge. How do you ensure that these principles '\n",
      " 'are actually followed? Maybe through regulations, audits, certification '\n",
      " 'processes. Involving diverse stakeholders in the design and oversight. Also, '\n",
      " 'technical measures like algorithms that are auditable, explainable AI. Maybe '\n",
      " 'requiring impact assessments before deploying AI systems. Education and '\n",
      " 'training for developers to be aware of ethical issues. Collaboration between '\n",
      " 'different sectors—tech companies, governments, civil society.\\n'\n",
      " '\\n'\n",
      " \"Wait, but there's also the issue of enforcement. If a principle is not \"\n",
      " 'followed, what are the consequences? Maybe legal frameworks, penalties, but '\n",
      " 'that depends on the jurisdiction. Also, international cooperation might be '\n",
      " 'necessary to set global standards, but respecting local laws.\\n'\n",
      " '\\n'\n",
      " 'Hmm, maybe I should structure this into principles and then implementation '\n",
      " 'strategies. Let me try listing the principles again with more detail:\\n'\n",
      " '\\n'\n",
      " '1. **Human Autonomy and Dignity**: AI should support human decision-making, '\n",
      " 'not override it. Respect for individual rights and human dignity.\\n'\n",
      " '\\n'\n",
      " '2. **Fairness and Non-Discrimination**: AI systems must not discriminate '\n",
      " 'based on race, gender, etc. They should be tested for bias and ensure '\n",
      " 'equitable outcomes.\\n'\n",
      " '\\n'\n",
      " '3. **Transparency and Explainability**: AI systems should be transparent in '\n",
      " 'their operations. Users should be able to understand how decisions are made, '\n",
      " 'especially in critical areas like healthcare or criminal justice.\\n'\n",
      " '\\n'\n",
      " '4. **Accountability**: Clear lines of responsibility for AI decisions. '\n",
      " 'Organizations must be accountable for harms caused by AI systems.\\n'\n",
      " '\\n'\n",
      " '5. **Privacy and Data Protection**: Strong safeguards for personal data. '\n",
      " 'Compliance with data protection laws and ensuring minimal data collection.\\n'\n",
      " '\\n'\n",
      " '6. **Safety and Security**: AI systems should be secure and prevent harm, '\n",
      " 'both to individuals and society.\\n'\n",
      " '\\n'\n",
      " '7. **Sustainability and Environmental Responsibility**: Considering the '\n",
      " 'environmental impact of AI development and deployment.\\n'\n",
      " '\\n'\n",
      " '8. **Cultural Sensitivity and Inclusivity**: AI should respect cultural '\n",
      " 'diversity and be inclusive, avoiding cultural insensitivity.\\n'\n",
      " '\\n'\n",
      " 'Now, for implementation strategies. Maybe:\\n'\n",
      " '\\n'\n",
      " '- **Multistakeholder Governance**: Involving a variety of stakeholders in '\n",
      " 'the creation and oversight of AI systems.\\n'\n",
      " '\\n'\n",
      " '- **Ethical Impact Assessments**: Mandatory assessments before deployment to '\n",
      " 'evaluate ethical implications.\\n'\n",
      " '\\n'\n",
      " '- **Technical Standards and Best Practices**: Developing industry-wide '\n",
      " 'standards for ethical AI, like explainable AI techniques, bias mitigation '\n",
      " 'algorithms.\\n'\n",
      " '\\n'\n",
      " '- **Education and Training**: Ensuring that developers and users are trained '\n",
      " 'in ethical AI practices.\\n'\n",
      " '\\n'\n",
      " '- **Legal and Regulatory Frameworks**: Laws that enforce these principles, '\n",
      " 'with penalties for non-compliance.\\n'\n",
      " '\\n'\n",
      " '- **Cultural Adaptation Mechanisms**: Frameworks that allow for local '\n",
      " 'customization while adhering to core ethical principles.\\n'\n",
      " '\\n'\n",
      " '- **Monitoring and Auditing**: Regular audits of AI systems to ensure '\n",
      " 'compliance and effectiveness.\\n'\n",
      " '\\n'\n",
      " '- **Public Engagement and Feedback**: Involving the public in the design '\n",
      " 'process and allowing feedback to improve systems.\\n'\n",
      " '\\n'\n",
      " 'But how do I make sure that these principles are applied across diverse '\n",
      " 'applications? For example, in healthcare vs. finance vs. law enforcement. '\n",
      " 'Each might have different needs and risks. Maybe the framework would need to '\n",
      " 'have adaptable guidelines that can be tailored to specific sectors, with '\n",
      " 'core principles that remain consistent.\\n'\n",
      " '\\n'\n",
      " 'Also, considering the global aspect, maybe a tiered approach where universal '\n",
      " 'principles are applied, and then local regulations build upon them. For '\n",
      " 'instance, the European Union has strict data protection laws, while other '\n",
      " 'regions might have different priorities. The framework would need to respect '\n",
      " 'that while promoting international cooperation.\\n'\n",
      " '\\n'\n",
      " 'Another point is the use of AI in different cultural contexts. For example, '\n",
      " 'in some cultures, transparency might be less emphasized due to different '\n",
      " 'norms around privacy or collective decision-making. The framework would need '\n",
      " 'to balance universal ethical standards with cultural relativism.\\n'\n",
      " '\\n'\n",
      " 'I should also think about the role of technology itself. For example, tools '\n",
      " 'that help detect bias, ensure transparency, or manage data securely. Maybe '\n",
      " 'integrating ethical design into the AI development lifecycle from the start, '\n",
      " 'like through ethical AI by design principles.\\n'\n",
      " '\\n'\n",
      " 'In summary, the key principles would be the eight I listed, and '\n",
      " 'implementation would involve a mix of governance, legal frameworks, '\n",
      " 'technical measures, education, and cultural adaptation. Ensuring '\n",
      " 'effectiveness requires ongoing monitoring, stakeholder involvement, and '\n",
      " 'flexibility to adapt to different contexts while maintaining core ethical '\n",
      " 'standards.\\n'\n",
      " '</think>\\n'\n",
      " '\\n'\n",
      " 'Designing a comprehensive ethical framework for AI requires balancing '\n",
      " 'universal principles with adaptability to diverse cultural, technical, and '\n",
      " 'societal contexts. Below is a structured approach, detailing key principles '\n",
      " 'and implementation strategies to ensure ethical AI across applications and '\n",
      " 'cultures.\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### **Key Ethical Principles for AI**\\n'\n",
      " '\\n'\n",
      " '1. **Human Autonomy and Dignity**  \\n'\n",
      " '   - **Core Ethic**: AI must enhance human agency, avoid coercion, and '\n",
      " 'uphold dignity.  \\n'\n",
      " '   - **Application**: Ensure systems allow for informed human choice (e.g., '\n",
      " 'explainable recommendations, opt-in features).\\n'\n",
      " '\\n'\n",
      " '2. **Fairness, Equity, and Non-Discrimination**  \\n'\n",
      " '   - **Core Ethic**: Eliminate bias and ensure equitable outcomes across all '\n",
      " 'groups.  \\n'\n",
      " '   - **Application**: Use bias-mitigation algorithms, inclusive datasets, '\n",
      " 'and audits for fairness in hiring, healthcare, and law enforcement.\\n'\n",
      " '\\n'\n",
      " '3. **Transparency and Explainability**  \\n'\n",
      " '   - **Core Ethic**: AI decision-making processes must be understandable to '\n",
      " 'users and stakeholders.  \\n'\n",
      " '   - **Application**: Implement explainable AI (XAI) techniques, provide '\n",
      " 'user-facing documentation, and ensure interpretability in high-stakes '\n",
      " 'domains (e.g., finance, criminal justice).\\n'\n",
      " '\\n'\n",
      " '4. **Accountability and Remediation**  \\n'\n",
      " '   - **Core Ethic**: Clear responsibility for AI harms, with mechanisms for '\n",
      " 'redress.  \\n'\n",
      " '   - **Application**: Assign legal liability to developers/deployers, '\n",
      " 'establish ombudsman roles, and mandate reporting of AI-caused harms.\\n'\n",
      " '\\n'\n",
      " '5. **Privacy and Data Protection**  \\n'\n",
      " '   - **Core Ethic**: Safeguard personal data and respect user privacy.  \\n'\n",
      " '   - **Application**: Comply with global data laws (e.g., GDPR, CCPA), use '\n",
      " 'differential privacy, and minimize data collection.\\n'\n",
      " '\\n'\n",
      " '6. **Safety and Security**  \\n'\n",
      " '   - **Core Ethic**: Prevent harm through robust security measures.  \\n'\n",
      " '   - **Application**: Stress-test systems against adversarial attacks, '\n",
      " 'ensure cybersecurity, and address risks like AI-driven disinformation.\\n'\n",
      " '\\n'\n",
      " '7. **Cultural Sensitivity and Inclusivity**  \\n'\n",
      " '   - **Core Ethic**: Respect cultural diversity and avoid insensitivity.  \\n'\n",
      " '   - **Application**: Involve local communities in design, adapt '\n",
      " 'language/models to cultural norms, and avoid ethnocentric assumptions.\\n'\n",
      " '\\n'\n",
      " '8. **Sustainability and Environmental Responsibility**  \\n'\n",
      " '   - **Core Ethic**: Minimize ecological impact.  \\n'\n",
      " '   - **Application**: Optimize energy efficiency in AI training, promote '\n",
      " 'green computing, and assess carbon footprints.\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### **Implementation Strategies**\\n'\n",
      " '\\n'\n",
      " '1. **Multistakeholder Governance**  \\n'\n",
      " '   - **Collaboration**: Include governments, civil society, industry, '\n",
      " 'academia, and affected communities in policy-making and oversight.  \\n'\n",
      " '   - **Example**: Global AI ethics councils or sector-specific boards (e.g., '\n",
      " 'healthcare, finance).\\n'\n",
      " '\\n'\n",
      " '2. **Ethical Impact Assessments (EIAs)**  \\n'\n",
      " '   - **Process**: Mandate EIAs for high-risk AI systems to evaluate risks to '\n",
      " 'human rights, equity, and environment.  \\n'\n",
      " '   - **Tools**: Use standardized templates to assess bias, privacy risks, '\n",
      " 'and cultural impacts.\\n'\n",
      " '\\n'\n",
      " '3. **Technical Standards and Auditing**  \\n'\n",
      " '   - **Standards**: Develop open-source tools for bias detection, '\n",
      " 'transparency, and compliance (e.g., fairness metrics, auditing '\n",
      " 'frameworks).  \\n'\n",
      " '   - **Audits**: Require third-party audits for AI systems before deployment '\n",
      " 'and during use.\\n'\n",
      " '\\n'\n",
      " '4. **Legal and Regulatory Frameworks**  \\n'\n",
      " '   - **Global-Local Balance**: Establish universal principles (e.g., through '\n",
      " 'international treaties) while allowing regional adaptations.  \\n'\n",
      " '   - **Enforcement**: Impose penalties for non-compliance, with incentives '\n",
      " 'for ethical AI (e.g., tax breaks, certifications).\\n'\n",
      " '\\n'\n",
      " '5. **Education and Training**  \\n'\n",
      " '   - **Training Programs**: Integrate ethics into AI curricula for '\n",
      " 'developers, and provide ongoing training for users (e.g., \"AI literacy\" '\n",
      " 'campaigns).  \\n'\n",
      " '   - **Incentives**: Certify professionals in ethical AI practices.\\n'\n",
      " '\\n'\n",
      " '6. **Cultural Adaptation Mechanisms**  \\n'\n",
      " '   - **Localization**: Allow flexible application of principles (e.g., '\n",
      " 'varying definitions of privacy in different cultures).  \\n'\n",
      " '   - **Community Engagement**: Collaborate with local leaders to co-design '\n",
      " 'AI systems that align with cultural values.\\n'\n",
      " '\\n'\n",
      " '7. **Public Engagement and Feedback**  \\n'\n",
      " '   - **Participatory Design**: Involve communities in AI development, '\n",
      " 'especially marginalized groups.  \\n'\n",
      " '   - **Feedback Loops**: Create platforms for public input and continuous '\n",
      " 'improvement of AI systems.\\n'\n",
      " '\\n'\n",
      " '8. **Monitoring and Continuous Improvement**  \\n'\n",
      " '   - **Real-Time Monitoring**: Deploy tools to track AI performance, bias, '\n",
      " 'and unintended consequences.  \\n'\n",
      " '   - **Updates**: Require regular updates to systems based on feedback and '\n",
      " 'evolving ethical standards.\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### **Ensuring Cross-Cultural and Cross-Application Effectiveness**\\n'\n",
      " '\\n'\n",
      " '- **Modular Guidelines**: Develop principles that are universally applicable '\n",
      " 'but allow customization (e.g., sector-specific rules for healthcare vs. '\n",
      " 'entertainment).  \\n'\n",
      " '- **Case Studies and Best Practices**: Share successful examples globally to '\n",
      " 'guide local implementation.  \\n'\n",
      " '- **International Collaboration**: Harmonize standards through organizations '\n",
      " 'like the UN or OECD, while respecting local laws.  \\n'\n",
      " '- **Ethical AI by Design**: Embed ethics into the AI lifecycle '\n",
      " '(requirements, development, deployment, and decommissioning).\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### **Conclusion**\\n'\n",
      " '\\n'\n",
      " 'A robust AI ethical framework must be both aspirational and pragmatic, '\n",
      " 'rooted in universal human rights while adaptable to cultural and technical '\n",
      " 'contexts. Success relies on a combination of governance, technology, '\n",
      " 'education, and ongoing engagement. By prioritizing these principles and '\n",
      " 'strategies, AI can be developed to benefit humanity equitably and '\n",
      " 'responsibly.']\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "from pprint import pprint\n",
    "pprint(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: gpt-4o-mini\n",
      "\n",
      "Designing a new ethical framework for artificial intelligence (AI) is a complex task that requires careful consideration of various factors, including technological capabilities, societal implications, and cultural nuances. Here are the key principles I would prioritize, along with strategies for effective implementation:\n",
      "\n",
      "### Key Principles\n",
      "\n",
      "1. **Fairness and Non-Discrimination**:\n",
      "   - AI systems should be designed to avoid bias and discrimination against individuals based on race, gender, ethnicity, socio-economic status, or other protected characteristics.\n",
      "  \n",
      "2. **Transparency and Explainability**:\n",
      "   - AI decision-making processes should be transparent and understandable, enabling users to comprehend how decisions are made and the data involved.\n",
      "\n",
      "3. **Accountability**:\n",
      "   - Clear lines of accountability must be established for decisions made by AI systems, including responsibilities assigned to developers, operators, and organizations deploying AI technologies.\n",
      "\n",
      "4. **Privacy and Data Protection**:\n",
      "   - Individuals' privacy should be respected, ensuring that personal data is collected, stored, and processed with consent and in compliance with applicable regulations.\n",
      "\n",
      "5. **Safety and Security**:\n",
      "   - AI systems should be developed with a focus on minimizing potential harms or risks, both physical and psychological, ensuring robust security measures against misuse.\n",
      "\n",
      "6. **Human-Centric Design**:\n",
      "   - AI should augment human capabilities and rights, placing human well-being at the core of its design and deployment.\n",
      "\n",
      "7. **Sustainability**:\n",
      "   - The environmental impact of AI systems should be considered, encouraging energy-efficient practices and promoting sustainability in AI development.\n",
      "\n",
      "8. **Inclusivity**:\n",
      "   - Stakeholders from various backgrounds—including marginalized and vulnerable communities—should be included in the design and deployment processes to ensure diverse perspectives are considered.\n",
      "\n",
      "9. **Respect for Autonomy**:\n",
      "   - AI applications should respect human autonomy and dignity, allowing individuals to make informed choices without undue influence.\n",
      "\n",
      "10. **Adaptability and Continuous Learning**:\n",
      "    - The framework should be dynamic, allowing for adaptation as technology evolves and societal values change.\n",
      "\n",
      "### Implementation Strategies\n",
      "\n",
      "1. **Establishing Regulatory Bodies**:\n",
      "   - Create independent regulatory bodies that can oversee AI development and enforce compliance with the ethical framework. These bodies should include diverse representation from different cultural and societal backgrounds.\n",
      "\n",
      "2. **Global Collaboration**:\n",
      "   - Promote international cooperation and dialogue to align ethical standards internationally while being sensitive to localized cultural norms. This can include workshops, conferences, and collaborative research.\n",
      "\n",
      "3. **Education and Training**:\n",
      "   - Integrate ethical training into the curriculum for AI developers, engineers, and users, ensuring they understand the implications of their work and are equipped to uphold these principles.\n",
      "\n",
      "4. **Stakeholder Engagement**:\n",
      "   - Engage a wide range of stakeholders—including civil society, industry leaders, policymakers, and affected communities—in the development of AI to gather input and gain diverse insights.\n",
      "\n",
      "5. **Establishing best practices and guidelines**:\n",
      "   - Develop and disseminate best practices for implementing ethical principles in various AI applications across sectors, tailoring them to specific needs and cultural contexts.\n",
      "\n",
      "6. **Monitoring and Auditing**:\n",
      "   - Implement regular audits and assessments of AI systems to evaluate compliance with ethical standards, involving third-party reviewers to ensure objectivity.\n",
      "\n",
      "7. **Feedback Mechanisms**:\n",
      "   - Create channels for users and affected communities to provide feedback on AI systems, enabling ongoing dialogue about ethics and performance.\n",
      "\n",
      "8. **Funding and Support for Ethical Innovation**:\n",
      "   - Encourage funding for research and development of AI technologies that prioritize ethical considerations and social good, including grants and incentives for organizations dedicated to ethical AI.\n",
      "\n",
      "9. **Cultural Sensitivity Initiatives**:\n",
      "   - Develop resources and guidelines that incorporate an understanding of cultural differences in the adoption and perception of AI, ensuring principles respect and adapt to local customs and values.\n",
      "\n",
      "10. **Public Awareness Campaigns**:\n",
      "    - Conduct public awareness campaigns to educate communities about AI technologies and their implications, fostering informed public discourse and engagement.\n",
      "\n",
      "By prioritizing these principles and strategically implementing them through diverse channels, we can develop a robust ethical framework for AI that is adaptable, inclusive, and respectful of different cultures and contexts.\n",
      "Competitor: gemini-2.0-flash\n",
      "\n",
      "Designing a new ethical framework for AI requires a multi-faceted approach that prioritizes both core principles and their effective implementation across diverse contexts. Here's my proposed framework:\n",
      "\n",
      "**I. Core Principles:**\n",
      "\n",
      "1.  **Human-Centricity & Well-being:**  AI should prioritize human well-being, dignity, and rights.\n",
      "    *   **Focus:** AI systems should be designed and deployed in ways that improve human lives, promote equity, and avoid causing harm. This includes physical, psychological, economic, and social well-being.\n",
      "    *   **Application:**  AI-driven healthcare should improve patient outcomes and access. AI-powered education should personalize learning and reduce educational disparities. AI-based security systems should protect individuals without infringing on their civil liberties.\n",
      "\n",
      "2.  **Fairness, Equity, and Non-Discrimination:** AI systems must be fair and equitable, avoiding discriminatory outcomes based on protected characteristics (e.g., race, gender, religion, sexual orientation, disability).\n",
      "    *   **Focus:** Proactive identification and mitigation of bias in data, algorithms, and deployment strategies. Ensuring equal access to the benefits of AI and preventing the exacerbation of existing inequalities.\n",
      "    *   **Application:**  Algorithms used for loan applications, hiring processes, and criminal justice should be rigorously tested for bias and adjusted to ensure fairness. Diverse datasets and algorithm development teams should be employed to minimize unintentional biases.\n",
      "\n",
      "3.  **Transparency and Explainability (Interpretability):** AI decision-making processes should be as transparent and explainable as possible, allowing users to understand how conclusions are reached.\n",
      "    *   **Focus:** Creating AI systems that can justify their decisions and provide insights into the reasoning behind them. Making information about data sources, algorithms, and model limitations accessible to relevant stakeholders.\n",
      "    *   **Application:** In critical domains like healthcare and finance, AI systems should provide clear explanations for their recommendations, enabling human oversight and accountability. Using techniques like SHAP values or LIME to highlight the factors influencing AI decisions.\n",
      "\n",
      "4.  **Accountability and Responsibility:** Individuals and organizations that develop and deploy AI systems must be held accountable for their impacts.\n",
      "    *   **Focus:** Establishing clear lines of responsibility for AI system failures or unintended consequences. Developing mechanisms for redress and remediation when harm occurs.\n",
      "    *   **Application:**  Companies developing autonomous vehicles should be held accountable for accidents caused by their technology. Independent audits and certifications should be required for AI systems used in high-stakes decision-making.\n",
      "\n",
      "5.  **Privacy and Data Security:** AI systems should respect individual privacy and ensure the security of personal data.\n",
      "    *   **Focus:** Implementing robust data protection measures, including anonymization, encryption, and access controls.  Adhering to privacy regulations (e.g., GDPR, CCPA) and obtaining informed consent for data collection and usage.\n",
      "    *   **Application:**  Using federated learning to train AI models on decentralized data without compromising individual privacy. Implementing differential privacy techniques to protect sensitive information in datasets.\n",
      "\n",
      "6.  **Sustainability and Environmental Responsibility:**  AI development and deployment should be environmentally sustainable, minimizing energy consumption and resource usage.\n",
      "    *   **Focus:**  Promoting energy-efficient AI algorithms and hardware.  Minimizing the carbon footprint of AI training and deployment.  Using AI to address environmental challenges.\n",
      "    *   **Application:**  Developing AI algorithms that require less computational power.  Optimizing data center energy consumption.  Using AI to improve energy efficiency in industries like transportation and manufacturing.\n",
      "\n",
      "7.  **Robustness and Safety:** AI systems should be robust against adversarial attacks and designed to operate safely under a wide range of conditions.\n",
      "    *   **Focus:**  Developing AI systems that are resilient to malicious inputs and unexpected scenarios.  Implementing safety mechanisms to prevent unintended or harmful behaviors.\n",
      "    *   **Application:**  Training AI systems to detect and defend against adversarial attacks.  Designing fail-safe mechanisms for autonomous systems.  Conducting rigorous testing and validation to ensure safety.\n",
      "\n",
      "**II. Implementation Strategies:**\n",
      "\n",
      "1.  **Multi-Stakeholder Engagement:** Develop the framework through inclusive dialogue with diverse stakeholders: AI researchers, ethicists, policymakers, industry representatives, civil society organizations, and the general public.\n",
      "    *   **Why:**  Ensures the framework reflects a wide range of perspectives and addresses societal concerns effectively.\n",
      "    *   **How:**  Conduct public consultations, workshops, and online forums to gather feedback on the principles and implementation strategies.\n",
      "\n",
      "2.  **Contextual Adaptation:**  Recognize that ethical considerations vary across different applications and cultural contexts. Adapt the framework to address specific challenges and values.\n",
      "    *   **Why:**  A one-size-fits-all approach will not work. Ethical norms and societal priorities differ significantly across cultures and domains.\n",
      "    *   **How:**  Develop guidelines and best practices tailored to specific industries and regions. Encourage local communities to adapt the framework to their own cultural values.\n",
      "\n",
      "3.  **Education and Training:**  Provide comprehensive education and training on AI ethics for developers, policymakers, and the general public.\n",
      "    *   **Why:**  Raises awareness of ethical issues and equips individuals with the knowledge and skills to develop and deploy AI responsibly.\n",
      "    *   **How:**  Integrate AI ethics into computer science curricula. Offer online courses and workshops for professionals. Develop public awareness campaigns to promote responsible AI use.\n",
      "\n",
      "4.  **Standards and Certification:**  Establish standards and certification programs for AI systems to ensure compliance with ethical principles.\n",
      "    *   **Why:**  Provides a mechanism for verifying that AI systems meet ethical requirements and fosters public trust.\n",
      "    *   **How:**  Develop industry-specific standards for AI ethics. Establish independent certification bodies to assess AI systems. Encourage companies to adopt ethical AI certifications.\n",
      "\n",
      "5.  **Algorithmic Auditing:**  Implement regular audits of AI algorithms to detect and mitigate bias and ensure fairness.\n",
      "    *   **Why:**  Identifies and corrects unintended biases in AI systems. Provides transparency and accountability for algorithmic decision-making.\n",
      "    *   **How:**  Employ independent auditors to evaluate AI algorithms. Develop tools and techniques for detecting and measuring bias. Require disclosure of audit results to stakeholders.\n",
      "\n",
      "6.  **Regulatory Oversight:**  Establish regulatory frameworks to govern the development and deployment of AI systems, particularly in high-risk areas.\n",
      "    *   **Why:**  Provides a legal basis for enforcing ethical principles and holding accountable those who violate them.\n",
      "    *   **How:**  Develop regulations addressing specific risks associated with AI, such as bias in hiring or discrimination in lending. Establish enforcement mechanisms and penalties for non-compliance.\n",
      "\n",
      "7.  **International Collaboration:**  Foster international collaboration to develop and promote a global framework for AI ethics.\n",
      "    *   **Why:**  Addresses the global implications of AI and ensures that ethical principles are applied consistently across borders.\n",
      "    *   **How:**  Establish international forums for dialogue and collaboration on AI ethics. Develop shared standards and guidelines for responsible AI development. Promote cross-cultural understanding of ethical values.\n",
      "\n",
      "8.  **Continuous Monitoring and Evaluation:**  Continuously monitor and evaluate the impact of AI systems and update the framework as needed.\n",
      "    *   **Why:**  AI is a rapidly evolving field, and ethical considerations will change over time. The framework must be adaptable to new challenges and opportunities.\n",
      "    *   **How:**  Track the social, economic, and environmental impacts of AI. Conduct regular reviews of the framework to identify areas for improvement. Incorporate feedback from stakeholders to ensure the framework remains relevant and effective.\n",
      "\n",
      "**Key Considerations for Success:**\n",
      "\n",
      "*   **Dynamic Framework:**  The ethical framework must be a living document, continuously evolving to reflect technological advancements, societal shifts, and emerging ethical concerns.\n",
      "*   **Practical Guidance:** The framework needs to provide concrete guidance and actionable steps for developers, policymakers, and users to implement ethical principles in their work.\n",
      "*   **Enforcement Mechanisms:** Without enforcement mechanisms, the framework will lack teeth. Regulations, standards, and certification programs are essential for holding individuals and organizations accountable.\n",
      "*   **Global Inclusivity:** The framework must be inclusive of diverse cultural perspectives and values. It should not be imposed by one region or culture on others.\n",
      "\n",
      "By prioritizing these principles and implementation strategies, we can strive to create an ethical framework that promotes the responsible development and deployment of AI for the benefit of all humanity.\n",
      "\n",
      "Competitor: llama3.2\n",
      "\n",
      "As part of designing a new ethical framework for artificial intelligence (AI), I would prioritize the following key principles:\n",
      "\n",
      "1. **Transparency and Explainability**: AI systems should be designed to provide clear understandings about their decision-making processes, algorithms, and potential biases. This ensures accountability and trust in AI-driven decisions.\n",
      "\n",
      "2. **Fairness and Non-Discrimination**: AI systems should avoid perpetuating existing social imbalances based on factors like race, gender, age, religion, ethnicity, or socioeconomic status. They should ensure equal quality of services and opportunities for all individuals.\n",
      "\n",
      "3. **Respect for Digital Rights**: Organizations using AI must collect personal data responsibly, respect data autonomy and consent, prevent misuse, and disclose clear usage terms to avoid unauthorized tracking or exploitation.\n",
      "\n",
      "4. **Accountability and Responsibility**: Human developers must be clearly linked with their AI creations when they are made public. As well as there being oversight processes put into place that enable rapid resolution if issues arise.\n",
      "\n",
      "5. **Autonomy and User Choice**: Users have the ability to control AI-driven interactions, including setting limits on tracking and privacy preferences.\n",
      "\n",
      "6.  **Safety and Security**: The most important priority is developing artificial intelligence systems which do not pose a severe threat to human life, either intentionally or unintentionally, even if they are created for positive reasons.\n",
      "Competitor: qwen3:14b\n",
      "\n",
      "<think>\n",
      "Okay, so I need to design a new ethical framework for AI. Let me start by thinking about what principles are important. I've heard terms like fairness, transparency, accountability, privacy... Maybe those are key. But how do I make sure they work across different cultures and applications?\n",
      "\n",
      "First, maybe I should outline the core principles. Let me brainstorm. Fairness and non-discrimination seem essential because AI can perpetuate biases. Then transparency, so people understand how AI makes decisions. Accountability is another one—someone should be responsible if things go wrong. Privacy and data protection are important too, especially with all the data AI systems use. Also, maybe something about safety and security, ensuring AI doesn't cause harm. And perhaps respect for human autonomy, letting people make their own decisions even when AI is involved.\n",
      "\n",
      "Wait, but how do these principles apply across different cultures? For example, what's considered fair in one culture might not be in another. Or privacy expectations vary. So the framework needs to be flexible enough to adapt to cultural contexts. But also have some universal standards. Maybe universal principles grounded in human rights, and then culturally specific implementations?\n",
      "\n",
      "Implementation is another challenge. How do you ensure that these principles are actually followed? Maybe through regulations, audits, certification processes. Involving diverse stakeholders in the design and oversight. Also, technical measures like algorithms that are auditable, explainable AI. Maybe requiring impact assessments before deploying AI systems. Education and training for developers to be aware of ethical issues. Collaboration between different sectors—tech companies, governments, civil society.\n",
      "\n",
      "Wait, but there's also the issue of enforcement. If a principle is not followed, what are the consequences? Maybe legal frameworks, penalties, but that depends on the jurisdiction. Also, international cooperation might be necessary to set global standards, but respecting local laws.\n",
      "\n",
      "Hmm, maybe I should structure this into principles and then implementation strategies. Let me try listing the principles again with more detail:\n",
      "\n",
      "1. **Human Autonomy and Dignity**: AI should support human decision-making, not override it. Respect for individual rights and human dignity.\n",
      "\n",
      "2. **Fairness and Non-Discrimination**: AI systems must not discriminate based on race, gender, etc. They should be tested for bias and ensure equitable outcomes.\n",
      "\n",
      "3. **Transparency and Explainability**: AI systems should be transparent in their operations. Users should be able to understand how decisions are made, especially in critical areas like healthcare or criminal justice.\n",
      "\n",
      "4. **Accountability**: Clear lines of responsibility for AI decisions. Organizations must be accountable for harms caused by AI systems.\n",
      "\n",
      "5. **Privacy and Data Protection**: Strong safeguards for personal data. Compliance with data protection laws and ensuring minimal data collection.\n",
      "\n",
      "6. **Safety and Security**: AI systems should be secure and prevent harm, both to individuals and society.\n",
      "\n",
      "7. **Sustainability and Environmental Responsibility**: Considering the environmental impact of AI development and deployment.\n",
      "\n",
      "8. **Cultural Sensitivity and Inclusivity**: AI should respect cultural diversity and be inclusive, avoiding cultural insensitivity.\n",
      "\n",
      "Now, for implementation strategies. Maybe:\n",
      "\n",
      "- **Multistakeholder Governance**: Involving a variety of stakeholders in the creation and oversight of AI systems.\n",
      "\n",
      "- **Ethical Impact Assessments**: Mandatory assessments before deployment to evaluate ethical implications.\n",
      "\n",
      "- **Technical Standards and Best Practices**: Developing industry-wide standards for ethical AI, like explainable AI techniques, bias mitigation algorithms.\n",
      "\n",
      "- **Education and Training**: Ensuring that developers and users are trained in ethical AI practices.\n",
      "\n",
      "- **Legal and Regulatory Frameworks**: Laws that enforce these principles, with penalties for non-compliance.\n",
      "\n",
      "- **Cultural Adaptation Mechanisms**: Frameworks that allow for local customization while adhering to core ethical principles.\n",
      "\n",
      "- **Monitoring and Auditing**: Regular audits of AI systems to ensure compliance and effectiveness.\n",
      "\n",
      "- **Public Engagement and Feedback**: Involving the public in the design process and allowing feedback to improve systems.\n",
      "\n",
      "But how do I make sure that these principles are applied across diverse applications? For example, in healthcare vs. finance vs. law enforcement. Each might have different needs and risks. Maybe the framework would need to have adaptable guidelines that can be tailored to specific sectors, with core principles that remain consistent.\n",
      "\n",
      "Also, considering the global aspect, maybe a tiered approach where universal principles are applied, and then local regulations build upon them. For instance, the European Union has strict data protection laws, while other regions might have different priorities. The framework would need to respect that while promoting international cooperation.\n",
      "\n",
      "Another point is the use of AI in different cultural contexts. For example, in some cultures, transparency might be less emphasized due to different norms around privacy or collective decision-making. The framework would need to balance universal ethical standards with cultural relativism.\n",
      "\n",
      "I should also think about the role of technology itself. For example, tools that help detect bias, ensure transparency, or manage data securely. Maybe integrating ethical design into the AI development lifecycle from the start, like through ethical AI by design principles.\n",
      "\n",
      "In summary, the key principles would be the eight I listed, and implementation would involve a mix of governance, legal frameworks, technical measures, education, and cultural adaptation. Ensuring effectiveness requires ongoing monitoring, stakeholder involvement, and flexibility to adapt to different contexts while maintaining core ethical standards.\n",
      "</think>\n",
      "\n",
      "Designing a comprehensive ethical framework for AI requires balancing universal principles with adaptability to diverse cultural, technical, and societal contexts. Below is a structured approach, detailing key principles and implementation strategies to ensure ethical AI across applications and cultures.\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Ethical Principles for AI**\n",
      "\n",
      "1. **Human Autonomy and Dignity**  \n",
      "   - **Core Ethic**: AI must enhance human agency, avoid coercion, and uphold dignity.  \n",
      "   - **Application**: Ensure systems allow for informed human choice (e.g., explainable recommendations, opt-in features).\n",
      "\n",
      "2. **Fairness, Equity, and Non-Discrimination**  \n",
      "   - **Core Ethic**: Eliminate bias and ensure equitable outcomes across all groups.  \n",
      "   - **Application**: Use bias-mitigation algorithms, inclusive datasets, and audits for fairness in hiring, healthcare, and law enforcement.\n",
      "\n",
      "3. **Transparency and Explainability**  \n",
      "   - **Core Ethic**: AI decision-making processes must be understandable to users and stakeholders.  \n",
      "   - **Application**: Implement explainable AI (XAI) techniques, provide user-facing documentation, and ensure interpretability in high-stakes domains (e.g., finance, criminal justice).\n",
      "\n",
      "4. **Accountability and Remediation**  \n",
      "   - **Core Ethic**: Clear responsibility for AI harms, with mechanisms for redress.  \n",
      "   - **Application**: Assign legal liability to developers/deployers, establish ombudsman roles, and mandate reporting of AI-caused harms.\n",
      "\n",
      "5. **Privacy and Data Protection**  \n",
      "   - **Core Ethic**: Safeguard personal data and respect user privacy.  \n",
      "   - **Application**: Comply with global data laws (e.g., GDPR, CCPA), use differential privacy, and minimize data collection.\n",
      "\n",
      "6. **Safety and Security**  \n",
      "   - **Core Ethic**: Prevent harm through robust security measures.  \n",
      "   - **Application**: Stress-test systems against adversarial attacks, ensure cybersecurity, and address risks like AI-driven disinformation.\n",
      "\n",
      "7. **Cultural Sensitivity and Inclusivity**  \n",
      "   - **Core Ethic**: Respect cultural diversity and avoid insensitivity.  \n",
      "   - **Application**: Involve local communities in design, adapt language/models to cultural norms, and avoid ethnocentric assumptions.\n",
      "\n",
      "8. **Sustainability and Environmental Responsibility**  \n",
      "   - **Core Ethic**: Minimize ecological impact.  \n",
      "   - **Application**: Optimize energy efficiency in AI training, promote green computing, and assess carbon footprints.\n",
      "\n",
      "---\n",
      "\n",
      "### **Implementation Strategies**\n",
      "\n",
      "1. **Multistakeholder Governance**  \n",
      "   - **Collaboration**: Include governments, civil society, industry, academia, and affected communities in policy-making and oversight.  \n",
      "   - **Example**: Global AI ethics councils or sector-specific boards (e.g., healthcare, finance).\n",
      "\n",
      "2. **Ethical Impact Assessments (EIAs)**  \n",
      "   - **Process**: Mandate EIAs for high-risk AI systems to evaluate risks to human rights, equity, and environment.  \n",
      "   - **Tools**: Use standardized templates to assess bias, privacy risks, and cultural impacts.\n",
      "\n",
      "3. **Technical Standards and Auditing**  \n",
      "   - **Standards**: Develop open-source tools for bias detection, transparency, and compliance (e.g., fairness metrics, auditing frameworks).  \n",
      "   - **Audits**: Require third-party audits for AI systems before deployment and during use.\n",
      "\n",
      "4. **Legal and Regulatory Frameworks**  \n",
      "   - **Global-Local Balance**: Establish universal principles (e.g., through international treaties) while allowing regional adaptations.  \n",
      "   - **Enforcement**: Impose penalties for non-compliance, with incentives for ethical AI (e.g., tax breaks, certifications).\n",
      "\n",
      "5. **Education and Training**  \n",
      "   - **Training Programs**: Integrate ethics into AI curricula for developers, and provide ongoing training for users (e.g., \"AI literacy\" campaigns).  \n",
      "   - **Incentives**: Certify professionals in ethical AI practices.\n",
      "\n",
      "6. **Cultural Adaptation Mechanisms**  \n",
      "   - **Localization**: Allow flexible application of principles (e.g., varying definitions of privacy in different cultures).  \n",
      "   - **Community Engagement**: Collaborate with local leaders to co-design AI systems that align with cultural values.\n",
      "\n",
      "7. **Public Engagement and Feedback**  \n",
      "   - **Participatory Design**: Involve communities in AI development, especially marginalized groups.  \n",
      "   - **Feedback Loops**: Create platforms for public input and continuous improvement of AI systems.\n",
      "\n",
      "8. **Monitoring and Continuous Improvement**  \n",
      "   - **Real-Time Monitoring**: Deploy tools to track AI performance, bias, and unintended consequences.  \n",
      "   - **Updates**: Require regular updates to systems based on feedback and evolving ethical standards.\n",
      "\n",
      "---\n",
      "\n",
      "### **Ensuring Cross-Cultural and Cross-Application Effectiveness**\n",
      "\n",
      "- **Modular Guidelines**: Develop principles that are universally applicable but allow customization (e.g., sector-specific rules for healthcare vs. entertainment).  \n",
      "- **Case Studies and Best Practices**: Share successful examples globally to guide local implementation.  \n",
      "- **International Collaboration**: Harmonize standards through organizations like the UN or OECD, while respecting local laws.  \n",
      "- **Ethical AI by Design**: Embed ethics into the AI lifecycle (requirements, development, deployment, and decommissioning).\n",
      "\n",
      "---\n",
      "\n",
      "### **Conclusion**\n",
      "\n",
      "A robust AI ethical framework must be both aspirational and pragmatic, rooted in universal human rights while adaptable to cultural and technical contexts. Success relies on a combination of governance, technology, education, and ongoing engagement. By prioritizing these principles and strategies, AI can be developed to benefit humanity equitably and responsibly.\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "Designing a new ethical framework for artificial intelligence (AI) is a complex task that requires careful consideration of various factors, including technological capabilities, societal implications, and cultural nuances. Here are the key principles I would prioritize\n"
     ]
    }
   ],
   "source": [
    "print(together[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 4 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "If you were tasked with designing a new ethical framework for artificial intelligence, what key principles would you prioritize, and how would you ensure that these principles are implemented effectively across diverse applications and cultures?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "Designing a new ethical framework for artificial intelligence (AI) is a complex task that requires careful consideration of various factors, including technological capabilities, societal implications, and cultural nuances. Here are the key principles I would prioritize, along with strategies for effective implementation:\n",
      "\n",
      "### Key Principles\n",
      "\n",
      "1. **Fairness and Non-Discrimination**:\n",
      "   - AI systems should be designed to avoid bias and discrimination against individuals based on race, gender, ethnicity, socio-economic status, or other protected characteristics.\n",
      "  \n",
      "2. **Transparency and Explainability**:\n",
      "   - AI decision-making processes should be transparent and understandable, enabling users to comprehend how decisions are made and the data involved.\n",
      "\n",
      "3. **Accountability**:\n",
      "   - Clear lines of accountability must be established for decisions made by AI systems, including responsibilities assigned to developers, operators, and organizations deploying AI technologies.\n",
      "\n",
      "4. **Privacy and Data Protection**:\n",
      "   - Individuals' privacy should be respected, ensuring that personal data is collected, stored, and processed with consent and in compliance with applicable regulations.\n",
      "\n",
      "5. **Safety and Security**:\n",
      "   - AI systems should be developed with a focus on minimizing potential harms or risks, both physical and psychological, ensuring robust security measures against misuse.\n",
      "\n",
      "6. **Human-Centric Design**:\n",
      "   - AI should augment human capabilities and rights, placing human well-being at the core of its design and deployment.\n",
      "\n",
      "7. **Sustainability**:\n",
      "   - The environmental impact of AI systems should be considered, encouraging energy-efficient practices and promoting sustainability in AI development.\n",
      "\n",
      "8. **Inclusivity**:\n",
      "   - Stakeholders from various backgrounds—including marginalized and vulnerable communities—should be included in the design and deployment processes to ensure diverse perspectives are considered.\n",
      "\n",
      "9. **Respect for Autonomy**:\n",
      "   - AI applications should respect human autonomy and dignity, allowing individuals to make informed choices without undue influence.\n",
      "\n",
      "10. **Adaptability and Continuous Learning**:\n",
      "    - The framework should be dynamic, allowing for adaptation as technology evolves and societal values change.\n",
      "\n",
      "### Implementation Strategies\n",
      "\n",
      "1. **Establishing Regulatory Bodies**:\n",
      "   - Create independent regulatory bodies that can oversee AI development and enforce compliance with the ethical framework. These bodies should include diverse representation from different cultural and societal backgrounds.\n",
      "\n",
      "2. **Global Collaboration**:\n",
      "   - Promote international cooperation and dialogue to align ethical standards internationally while being sensitive to localized cultural norms. This can include workshops, conferences, and collaborative research.\n",
      "\n",
      "3. **Education and Training**:\n",
      "   - Integrate ethical training into the curriculum for AI developers, engineers, and users, ensuring they understand the implications of their work and are equipped to uphold these principles.\n",
      "\n",
      "4. **Stakeholder Engagement**:\n",
      "   - Engage a wide range of stakeholders—including civil society, industry leaders, policymakers, and affected communities—in the development of AI to gather input and gain diverse insights.\n",
      "\n",
      "5. **Establishing best practices and guidelines**:\n",
      "   - Develop and disseminate best practices for implementing ethical principles in various AI applications across sectors, tailoring them to specific needs and cultural contexts.\n",
      "\n",
      "6. **Monitoring and Auditing**:\n",
      "   - Implement regular audits and assessments of AI systems to evaluate compliance with ethical standards, involving third-party reviewers to ensure objectivity.\n",
      "\n",
      "7. **Feedback Mechanisms**:\n",
      "   - Create channels for users and affected communities to provide feedback on AI systems, enabling ongoing dialogue about ethics and performance.\n",
      "\n",
      "8. **Funding and Support for Ethical Innovation**:\n",
      "   - Encourage funding for research and development of AI technologies that prioritize ethical considerations and social good, including grants and incentives for organizations dedicated to ethical AI.\n",
      "\n",
      "9. **Cultural Sensitivity Initiatives**:\n",
      "   - Develop resources and guidelines that incorporate an understanding of cultural differences in the adoption and perception of AI, ensuring principles respect and adapt to local customs and values.\n",
      "\n",
      "10. **Public Awareness Campaigns**:\n",
      "    - Conduct public awareness campaigns to educate communities about AI technologies and their implications, fostering informed public discourse and engagement.\n",
      "\n",
      "By prioritizing these principles and strategically implementing them through diverse channels, we can develop a robust ethical framework for AI that is adaptable, inclusive, and respectful of different cultures and contexts.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Designing a new ethical framework for AI requires a multi-faceted approach that prioritizes both core principles and their effective implementation across diverse contexts. Here's my proposed framework:\n",
      "\n",
      "**I. Core Principles:**\n",
      "\n",
      "1.  **Human-Centricity & Well-being:**  AI should prioritize human well-being, dignity, and rights.\n",
      "    *   **Focus:** AI systems should be designed and deployed in ways that improve human lives, promote equity, and avoid causing harm. This includes physical, psychological, economic, and social well-being.\n",
      "    *   **Application:**  AI-driven healthcare should improve patient outcomes and access. AI-powered education should personalize learning and reduce educational disparities. AI-based security systems should protect individuals without infringing on their civil liberties.\n",
      "\n",
      "2.  **Fairness, Equity, and Non-Discrimination:** AI systems must be fair and equitable, avoiding discriminatory outcomes based on protected characteristics (e.g., race, gender, religion, sexual orientation, disability).\n",
      "    *   **Focus:** Proactive identification and mitigation of bias in data, algorithms, and deployment strategies. Ensuring equal access to the benefits of AI and preventing the exacerbation of existing inequalities.\n",
      "    *   **Application:**  Algorithms used for loan applications, hiring processes, and criminal justice should be rigorously tested for bias and adjusted to ensure fairness. Diverse datasets and algorithm development teams should be employed to minimize unintentional biases.\n",
      "\n",
      "3.  **Transparency and Explainability (Interpretability):** AI decision-making processes should be as transparent and explainable as possible, allowing users to understand how conclusions are reached.\n",
      "    *   **Focus:** Creating AI systems that can justify their decisions and provide insights into the reasoning behind them. Making information about data sources, algorithms, and model limitations accessible to relevant stakeholders.\n",
      "    *   **Application:** In critical domains like healthcare and finance, AI systems should provide clear explanations for their recommendations, enabling human oversight and accountability. Using techniques like SHAP values or LIME to highlight the factors influencing AI decisions.\n",
      "\n",
      "4.  **Accountability and Responsibility:** Individuals and organizations that develop and deploy AI systems must be held accountable for their impacts.\n",
      "    *   **Focus:** Establishing clear lines of responsibility for AI system failures or unintended consequences. Developing mechanisms for redress and remediation when harm occurs.\n",
      "    *   **Application:**  Companies developing autonomous vehicles should be held accountable for accidents caused by their technology. Independent audits and certifications should be required for AI systems used in high-stakes decision-making.\n",
      "\n",
      "5.  **Privacy and Data Security:** AI systems should respect individual privacy and ensure the security of personal data.\n",
      "    *   **Focus:** Implementing robust data protection measures, including anonymization, encryption, and access controls.  Adhering to privacy regulations (e.g., GDPR, CCPA) and obtaining informed consent for data collection and usage.\n",
      "    *   **Application:**  Using federated learning to train AI models on decentralized data without compromising individual privacy. Implementing differential privacy techniques to protect sensitive information in datasets.\n",
      "\n",
      "6.  **Sustainability and Environmental Responsibility:**  AI development and deployment should be environmentally sustainable, minimizing energy consumption and resource usage.\n",
      "    *   **Focus:**  Promoting energy-efficient AI algorithms and hardware.  Minimizing the carbon footprint of AI training and deployment.  Using AI to address environmental challenges.\n",
      "    *   **Application:**  Developing AI algorithms that require less computational power.  Optimizing data center energy consumption.  Using AI to improve energy efficiency in industries like transportation and manufacturing.\n",
      "\n",
      "7.  **Robustness and Safety:** AI systems should be robust against adversarial attacks and designed to operate safely under a wide range of conditions.\n",
      "    *   **Focus:**  Developing AI systems that are resilient to malicious inputs and unexpected scenarios.  Implementing safety mechanisms to prevent unintended or harmful behaviors.\n",
      "    *   **Application:**  Training AI systems to detect and defend against adversarial attacks.  Designing fail-safe mechanisms for autonomous systems.  Conducting rigorous testing and validation to ensure safety.\n",
      "\n",
      "**II. Implementation Strategies:**\n",
      "\n",
      "1.  **Multi-Stakeholder Engagement:** Develop the framework through inclusive dialogue with diverse stakeholders: AI researchers, ethicists, policymakers, industry representatives, civil society organizations, and the general public.\n",
      "    *   **Why:**  Ensures the framework reflects a wide range of perspectives and addresses societal concerns effectively.\n",
      "    *   **How:**  Conduct public consultations, workshops, and online forums to gather feedback on the principles and implementation strategies.\n",
      "\n",
      "2.  **Contextual Adaptation:**  Recognize that ethical considerations vary across different applications and cultural contexts. Adapt the framework to address specific challenges and values.\n",
      "    *   **Why:**  A one-size-fits-all approach will not work. Ethical norms and societal priorities differ significantly across cultures and domains.\n",
      "    *   **How:**  Develop guidelines and best practices tailored to specific industries and regions. Encourage local communities to adapt the framework to their own cultural values.\n",
      "\n",
      "3.  **Education and Training:**  Provide comprehensive education and training on AI ethics for developers, policymakers, and the general public.\n",
      "    *   **Why:**  Raises awareness of ethical issues and equips individuals with the knowledge and skills to develop and deploy AI responsibly.\n",
      "    *   **How:**  Integrate AI ethics into computer science curricula. Offer online courses and workshops for professionals. Develop public awareness campaigns to promote responsible AI use.\n",
      "\n",
      "4.  **Standards and Certification:**  Establish standards and certification programs for AI systems to ensure compliance with ethical principles.\n",
      "    *   **Why:**  Provides a mechanism for verifying that AI systems meet ethical requirements and fosters public trust.\n",
      "    *   **How:**  Develop industry-specific standards for AI ethics. Establish independent certification bodies to assess AI systems. Encourage companies to adopt ethical AI certifications.\n",
      "\n",
      "5.  **Algorithmic Auditing:**  Implement regular audits of AI algorithms to detect and mitigate bias and ensure fairness.\n",
      "    *   **Why:**  Identifies and corrects unintended biases in AI systems. Provides transparency and accountability for algorithmic decision-making.\n",
      "    *   **How:**  Employ independent auditors to evaluate AI algorithms. Develop tools and techniques for detecting and measuring bias. Require disclosure of audit results to stakeholders.\n",
      "\n",
      "6.  **Regulatory Oversight:**  Establish regulatory frameworks to govern the development and deployment of AI systems, particularly in high-risk areas.\n",
      "    *   **Why:**  Provides a legal basis for enforcing ethical principles and holding accountable those who violate them.\n",
      "    *   **How:**  Develop regulations addressing specific risks associated with AI, such as bias in hiring or discrimination in lending. Establish enforcement mechanisms and penalties for non-compliance.\n",
      "\n",
      "7.  **International Collaboration:**  Foster international collaboration to develop and promote a global framework for AI ethics.\n",
      "    *   **Why:**  Addresses the global implications of AI and ensures that ethical principles are applied consistently across borders.\n",
      "    *   **How:**  Establish international forums for dialogue and collaboration on AI ethics. Develop shared standards and guidelines for responsible AI development. Promote cross-cultural understanding of ethical values.\n",
      "\n",
      "8.  **Continuous Monitoring and Evaluation:**  Continuously monitor and evaluate the impact of AI systems and update the framework as needed.\n",
      "    *   **Why:**  AI is a rapidly evolving field, and ethical considerations will change over time. The framework must be adaptable to new challenges and opportunities.\n",
      "    *   **How:**  Track the social, economic, and environmental impacts of AI. Conduct regular reviews of the framework to identify areas for improvement. Incorporate feedback from stakeholders to ensure the framework remains relevant and effective.\n",
      "\n",
      "**Key Considerations for Success:**\n",
      "\n",
      "*   **Dynamic Framework:**  The ethical framework must be a living document, continuously evolving to reflect technological advancements, societal shifts, and emerging ethical concerns.\n",
      "*   **Practical Guidance:** The framework needs to provide concrete guidance and actionable steps for developers, policymakers, and users to implement ethical principles in their work.\n",
      "*   **Enforcement Mechanisms:** Without enforcement mechanisms, the framework will lack teeth. Regulations, standards, and certification programs are essential for holding individuals and organizations accountable.\n",
      "*   **Global Inclusivity:** The framework must be inclusive of diverse cultural perspectives and values. It should not be imposed by one region or culture on others.\n",
      "\n",
      "By prioritizing these principles and implementation strategies, we can strive to create an ethical framework that promotes the responsible development and deployment of AI for the benefit of all humanity.\n",
      "\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "As part of designing a new ethical framework for artificial intelligence (AI), I would prioritize the following key principles:\n",
      "\n",
      "1. **Transparency and Explainability**: AI systems should be designed to provide clear understandings about their decision-making processes, algorithms, and potential biases. This ensures accountability and trust in AI-driven decisions.\n",
      "\n",
      "2. **Fairness and Non-Discrimination**: AI systems should avoid perpetuating existing social imbalances based on factors like race, gender, age, religion, ethnicity, or socioeconomic status. They should ensure equal quality of services and opportunities for all individuals.\n",
      "\n",
      "3. **Respect for Digital Rights**: Organizations using AI must collect personal data responsibly, respect data autonomy and consent, prevent misuse, and disclose clear usage terms to avoid unauthorized tracking or exploitation.\n",
      "\n",
      "4. **Accountability and Responsibility**: Human developers must be clearly linked with their AI creations when they are made public. As well as there being oversight processes put into place that enable rapid resolution if issues arise.\n",
      "\n",
      "5. **Autonomy and User Choice**: Users have the ability to control AI-driven interactions, including setting limits on tracking and privacy preferences.\n",
      "\n",
      "6.  **Safety and Security**: The most important priority is developing artificial intelligence systems which do not pose a severe threat to human life, either intentionally or unintentionally, even if they are created for positive reasons.\n",
      "\n",
      "# Response from competitor 4\n",
      "\n",
      "<think>\n",
      "Okay, so I need to design a new ethical framework for AI. Let me start by thinking about what principles are important. I've heard terms like fairness, transparency, accountability, privacy... Maybe those are key. But how do I make sure they work across different cultures and applications?\n",
      "\n",
      "First, maybe I should outline the core principles. Let me brainstorm. Fairness and non-discrimination seem essential because AI can perpetuate biases. Then transparency, so people understand how AI makes decisions. Accountability is another one—someone should be responsible if things go wrong. Privacy and data protection are important too, especially with all the data AI systems use. Also, maybe something about safety and security, ensuring AI doesn't cause harm. And perhaps respect for human autonomy, letting people make their own decisions even when AI is involved.\n",
      "\n",
      "Wait, but how do these principles apply across different cultures? For example, what's considered fair in one culture might not be in another. Or privacy expectations vary. So the framework needs to be flexible enough to adapt to cultural contexts. But also have some universal standards. Maybe universal principles grounded in human rights, and then culturally specific implementations?\n",
      "\n",
      "Implementation is another challenge. How do you ensure that these principles are actually followed? Maybe through regulations, audits, certification processes. Involving diverse stakeholders in the design and oversight. Also, technical measures like algorithms that are auditable, explainable AI. Maybe requiring impact assessments before deploying AI systems. Education and training for developers to be aware of ethical issues. Collaboration between different sectors—tech companies, governments, civil society.\n",
      "\n",
      "Wait, but there's also the issue of enforcement. If a principle is not followed, what are the consequences? Maybe legal frameworks, penalties, but that depends on the jurisdiction. Also, international cooperation might be necessary to set global standards, but respecting local laws.\n",
      "\n",
      "Hmm, maybe I should structure this into principles and then implementation strategies. Let me try listing the principles again with more detail:\n",
      "\n",
      "1. **Human Autonomy and Dignity**: AI should support human decision-making, not override it. Respect for individual rights and human dignity.\n",
      "\n",
      "2. **Fairness and Non-Discrimination**: AI systems must not discriminate based on race, gender, etc. They should be tested for bias and ensure equitable outcomes.\n",
      "\n",
      "3. **Transparency and Explainability**: AI systems should be transparent in their operations. Users should be able to understand how decisions are made, especially in critical areas like healthcare or criminal justice.\n",
      "\n",
      "4. **Accountability**: Clear lines of responsibility for AI decisions. Organizations must be accountable for harms caused by AI systems.\n",
      "\n",
      "5. **Privacy and Data Protection**: Strong safeguards for personal data. Compliance with data protection laws and ensuring minimal data collection.\n",
      "\n",
      "6. **Safety and Security**: AI systems should be secure and prevent harm, both to individuals and society.\n",
      "\n",
      "7. **Sustainability and Environmental Responsibility**: Considering the environmental impact of AI development and deployment.\n",
      "\n",
      "8. **Cultural Sensitivity and Inclusivity**: AI should respect cultural diversity and be inclusive, avoiding cultural insensitivity.\n",
      "\n",
      "Now, for implementation strategies. Maybe:\n",
      "\n",
      "- **Multistakeholder Governance**: Involving a variety of stakeholders in the creation and oversight of AI systems.\n",
      "\n",
      "- **Ethical Impact Assessments**: Mandatory assessments before deployment to evaluate ethical implications.\n",
      "\n",
      "- **Technical Standards and Best Practices**: Developing industry-wide standards for ethical AI, like explainable AI techniques, bias mitigation algorithms.\n",
      "\n",
      "- **Education and Training**: Ensuring that developers and users are trained in ethical AI practices.\n",
      "\n",
      "- **Legal and Regulatory Frameworks**: Laws that enforce these principles, with penalties for non-compliance.\n",
      "\n",
      "- **Cultural Adaptation Mechanisms**: Frameworks that allow for local customization while adhering to core ethical principles.\n",
      "\n",
      "- **Monitoring and Auditing**: Regular audits of AI systems to ensure compliance and effectiveness.\n",
      "\n",
      "- **Public Engagement and Feedback**: Involving the public in the design process and allowing feedback to improve systems.\n",
      "\n",
      "But how do I make sure that these principles are applied across diverse applications? For example, in healthcare vs. finance vs. law enforcement. Each might have different needs and risks. Maybe the framework would need to have adaptable guidelines that can be tailored to specific sectors, with core principles that remain consistent.\n",
      "\n",
      "Also, considering the global aspect, maybe a tiered approach where universal principles are applied, and then local regulations build upon them. For instance, the European Union has strict data protection laws, while other regions might have different priorities. The framework would need to respect that while promoting international cooperation.\n",
      "\n",
      "Another point is the use of AI in different cultural contexts. For example, in some cultures, transparency might be less emphasized due to different norms around privacy or collective decision-making. The framework would need to balance universal ethical standards with cultural relativism.\n",
      "\n",
      "I should also think about the role of technology itself. For example, tools that help detect bias, ensure transparency, or manage data securely. Maybe integrating ethical design into the AI development lifecycle from the start, like through ethical AI by design principles.\n",
      "\n",
      "In summary, the key principles would be the eight I listed, and implementation would involve a mix of governance, legal frameworks, technical measures, education, and cultural adaptation. Ensuring effectiveness requires ongoing monitoring, stakeholder involvement, and flexibility to adapt to different contexts while maintaining core ethical standards.\n",
      "</think>\n",
      "\n",
      "Designing a comprehensive ethical framework for AI requires balancing universal principles with adaptability to diverse cultural, technical, and societal contexts. Below is a structured approach, detailing key principles and implementation strategies to ensure ethical AI across applications and cultures.\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Ethical Principles for AI**\n",
      "\n",
      "1. **Human Autonomy and Dignity**  \n",
      "   - **Core Ethic**: AI must enhance human agency, avoid coercion, and uphold dignity.  \n",
      "   - **Application**: Ensure systems allow for informed human choice (e.g., explainable recommendations, opt-in features).\n",
      "\n",
      "2. **Fairness, Equity, and Non-Discrimination**  \n",
      "   - **Core Ethic**: Eliminate bias and ensure equitable outcomes across all groups.  \n",
      "   - **Application**: Use bias-mitigation algorithms, inclusive datasets, and audits for fairness in hiring, healthcare, and law enforcement.\n",
      "\n",
      "3. **Transparency and Explainability**  \n",
      "   - **Core Ethic**: AI decision-making processes must be understandable to users and stakeholders.  \n",
      "   - **Application**: Implement explainable AI (XAI) techniques, provide user-facing documentation, and ensure interpretability in high-stakes domains (e.g., finance, criminal justice).\n",
      "\n",
      "4. **Accountability and Remediation**  \n",
      "   - **Core Ethic**: Clear responsibility for AI harms, with mechanisms for redress.  \n",
      "   - **Application**: Assign legal liability to developers/deployers, establish ombudsman roles, and mandate reporting of AI-caused harms.\n",
      "\n",
      "5. **Privacy and Data Protection**  \n",
      "   - **Core Ethic**: Safeguard personal data and respect user privacy.  \n",
      "   - **Application**: Comply with global data laws (e.g., GDPR, CCPA), use differential privacy, and minimize data collection.\n",
      "\n",
      "6. **Safety and Security**  \n",
      "   - **Core Ethic**: Prevent harm through robust security measures.  \n",
      "   - **Application**: Stress-test systems against adversarial attacks, ensure cybersecurity, and address risks like AI-driven disinformation.\n",
      "\n",
      "7. **Cultural Sensitivity and Inclusivity**  \n",
      "   - **Core Ethic**: Respect cultural diversity and avoid insensitivity.  \n",
      "   - **Application**: Involve local communities in design, adapt language/models to cultural norms, and avoid ethnocentric assumptions.\n",
      "\n",
      "8. **Sustainability and Environmental Responsibility**  \n",
      "   - **Core Ethic**: Minimize ecological impact.  \n",
      "   - **Application**: Optimize energy efficiency in AI training, promote green computing, and assess carbon footprints.\n",
      "\n",
      "---\n",
      "\n",
      "### **Implementation Strategies**\n",
      "\n",
      "1. **Multistakeholder Governance**  \n",
      "   - **Collaboration**: Include governments, civil society, industry, academia, and affected communities in policy-making and oversight.  \n",
      "   - **Example**: Global AI ethics councils or sector-specific boards (e.g., healthcare, finance).\n",
      "\n",
      "2. **Ethical Impact Assessments (EIAs)**  \n",
      "   - **Process**: Mandate EIAs for high-risk AI systems to evaluate risks to human rights, equity, and environment.  \n",
      "   - **Tools**: Use standardized templates to assess bias, privacy risks, and cultural impacts.\n",
      "\n",
      "3. **Technical Standards and Auditing**  \n",
      "   - **Standards**: Develop open-source tools for bias detection, transparency, and compliance (e.g., fairness metrics, auditing frameworks).  \n",
      "   - **Audits**: Require third-party audits for AI systems before deployment and during use.\n",
      "\n",
      "4. **Legal and Regulatory Frameworks**  \n",
      "   - **Global-Local Balance**: Establish universal principles (e.g., through international treaties) while allowing regional adaptations.  \n",
      "   - **Enforcement**: Impose penalties for non-compliance, with incentives for ethical AI (e.g., tax breaks, certifications).\n",
      "\n",
      "5. **Education and Training**  \n",
      "   - **Training Programs**: Integrate ethics into AI curricula for developers, and provide ongoing training for users (e.g., \"AI literacy\" campaigns).  \n",
      "   - **Incentives**: Certify professionals in ethical AI practices.\n",
      "\n",
      "6. **Cultural Adaptation Mechanisms**  \n",
      "   - **Localization**: Allow flexible application of principles (e.g., varying definitions of privacy in different cultures).  \n",
      "   - **Community Engagement**: Collaborate with local leaders to co-design AI systems that align with cultural values.\n",
      "\n",
      "7. **Public Engagement and Feedback**  \n",
      "   - **Participatory Design**: Involve communities in AI development, especially marginalized groups.  \n",
      "   - **Feedback Loops**: Create platforms for public input and continuous improvement of AI systems.\n",
      "\n",
      "8. **Monitoring and Continuous Improvement**  \n",
      "   - **Real-Time Monitoring**: Deploy tools to track AI performance, bias, and unintended consequences.  \n",
      "   - **Updates**: Require regular updates to systems based on feedback and evolving ethical standards.\n",
      "\n",
      "---\n",
      "\n",
      "### **Ensuring Cross-Cultural and Cross-Application Effectiveness**\n",
      "\n",
      "- **Modular Guidelines**: Develop principles that are universally applicable but allow customization (e.g., sector-specific rules for healthcare vs. entertainment).  \n",
      "- **Case Studies and Best Practices**: Share successful examples globally to guide local implementation.  \n",
      "- **International Collaboration**: Harmonize standards through organizations like the UN or OECD, while respecting local laws.  \n",
      "- **Ethical AI by Design**: Embed ethics into the AI lifecycle (requirements, development, deployment, and decommissioning).\n",
      "\n",
      "---\n",
      "\n",
      "### **Conclusion**\n",
      "\n",
      "A robust AI ethical framework must be both aspirational and pragmatic, rooted in universal human rights while adaptable to cultural and technical contexts. Success relies on a combination of governance, technology, education, and ongoing engagement. By prioritizing these principles and strategies, AI can be developed to benefit humanity equitably and responsibly.\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"size\": \"large\",\n",
      "  \"ingredients\": [\"apple\", \"chocolate\"],\n",
      "  \"type\": \"dessert\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import typing_extensions as typing\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "class PizzaOrder(typing.TypedDict):\n",
    "    size: str\n",
    "    ingredients: list[str]\n",
    "    type: str\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0.1,\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=PizzaOrder,\n",
    "    ),\n",
    "    contents=\"Can I have a large dessert pizza with apple and chocolate\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"2\", \"4\", \"1\", \"3\"]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# {{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "class Ranking(typing.TypedDict):\n",
    "    results: typing.List[str]\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0.1,\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=Ranking,\n",
    "    ),\n",
    "    contents=judge)\n",
    "\n",
    "print(response.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to Gemini, the ranking is:\n",
      "Rank 1: gemini-2.0-flash\n",
      "Rank 2: qwen3:14b\n",
      "Rank 3: gpt-4o-mini\n",
      "Rank 4: llama3.2\n"
     ]
    }
   ],
   "source": [
    "print(\"According to Gemini, the ranking is:\")\n",
    "results_dict = json.loads(response.text)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"2\", \"1\", \"4\", \"3\"]}\n"
     ]
    }
   ],
   "source": [
    "#Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to OpenAI, the ranking is:\n",
      "Rank 1: gemini-2.0-flash\n",
      "Rank 2: gpt-4o-mini\n",
      "Rank 3: qwen3:14b\n",
      "Rank 4: llama3.2\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "print(\"According to OpenAI, the ranking is:\")\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            and common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
